<!DOCTYPE html>
<html lang="en">
  <head>
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <title>Manopt, tutorial</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="Nicolas Boumal">
    <link href="favicon.ico" rel="icon" type="image/x-icon">
    <!-- Le styles -->
    <link href="bootstrap/css/bootstrap.css" rel="stylesheet">
    <style type="text/css">
body {
        padding-top: 80px;
        padding-bottom: 40px;
}
      thead {
        font-weight: bold;
      }
    </style>
    <link href="bootstrap/css/bootstrap-responsive.css" rel="stylesheet">
    <!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>    <![endif]-->
    <link href="bootstrap/css/prettify.css" type="text/css" rel="stylesheet">
    <link href="bootstrap/css/lang-matlab.css" type="text/css" rel="stylesheet">
  </head>
  <body onload="prettyPrint()" data-spy="scroll" data-target=".sidebar">
    <div class="navbar navbar-fixed-top">
      <div class="navbar-inner"> <a class="btn btn-navbar" data-toggle="collapse"
          data-target=".nav-collapse"> <span class="icon-bar"></span> <span class="icon-bar"></span>
          <span class="icon-bar"></span> </a>
        <div class="container"> <a class="brand" href="index.html">Manopt</a>
          <div class="nav-collapse collapse">
            <ul class="nav">
              <li><a href="index.html"><i class="icon-home">&#160;</i> Home</a></li>
              <li class="active"><a href="tutorial.html"><i class="icon-road">&#160;</i>
                  Tutorial</a></li>
              <li><a href="downloads.html"><i class="icon-download-alt">&#160;</i>
                  Downloads</a></li>
              <li><a href="forum.html"><i class="icon-edit">&#160;</i> Forum</a></li>
              <li><a href="about.html"><i class="icon-user">&#160;</i> About</a></li>
              <li><a href="#contactmodal" data-toggle="modal"><i class="icon-envelope">&#160;</i>
                  Contact</a></li>
            </ul>
          </div>
          <!--/.nav-collapse --> </div>
      </div>
    </div>
    <!-- Contact modal Begin -->
    <div id="contactmodal" class="modal hide fade" tabindex="-1" role="dialog" aria-labelledby="myModalLabel"
      aria-hidden="true">
      <div class="modal-header"> <button type="button" class="close" data-dismiss="modal"
          aria-hidden="true">&#215;</button>
        <h3 id="myModalLabel">To contact us</h3>
      </div>
      <div class="modal-body">
        <p>To discuss code, it is best to use the <a href="forum.html">forum</a>.</p>
        <p>For things not suitable for the forum, e-mail us at <a href="mailto:manopttoolbox@gmail.com">manopttoolbox@gmail.com</a>.</p>
        <p>We are happy to receive feedback and bug reports or requests for more
          features, to discuss the toolbox in general as well as its
          documentation and to help you use it.</p>
        <p>We would also love to know how you use the toolbox, and if you built
          nice manifold factories, solvers or tools that could benefit others.</p>
      </div>
      <div class="modal-footer"> <button class="btn" data-dismiss="modal" aria-hidden="true">Close</button>
      </div>
    </div>
    <!-- Contact modal End -->
    <div class="container">
      <div class="row">
        <div class="span3 sidebar" style="min-height: 1px">
          <!--Sidebar content-->
          <!-- class="nav nav-tabs nav-stacked mysidebar" -->
          <ul class="nav nav-list mysidebar" data-spy="affix">
            <li class="nav-header">Tutorial</li>
            <li><a href="#gettingstarted">Getting started</a></li>
            <li><a href="#firstexample">A first example</a></li>
            <li><a href="#manifolds">Manifolds</a></li>
            <li><a href="#solvers">Solvers</a></li>
            <li><a href="#costdescription">Describing the cost</a></li>
            <li><a href="#tools">Helpful tools</a></li>
            <li><a href="#core">Core tools</a></li>
            <li><a href="#reference">Reference</a></li>
          </ul>
        </div>
        <div class="span9">
          <!--Body content-->
          <section id="gettingstarted">
            <div class="page-header">
              <h1>Getting started with Manopt </h1>
            </div>
            <h3>Foreword</h3>
            <p><strong>With Manopt, you can solve optimization problems on
                manifolds</strong> using state-of-the-art algorithms, with
              minimal effort. The toolbox targets great flexibility in the
              problem description and comes with advanced features, such as
              caching.</p>
            <p>The toolbox architecture is based on a <strong>separation of the
                manifolds, the solvers and the problem descriptions</strong>.
              For basic use, one only needs to pick a manifold from the library,
              describe the cost function (and possible derivatives) on this
              manifold and pass it on to a solver. Accompanying tools help the
              user in common tasks such as numerically checking whether the cost
              function agrees with its derivatives up to the appropriate order
              etc.</p>
            <p><strong>This is a </strong><strong>prototyping toolbox</strong>,
              designed based on the idea that the costly part of solving an
              optimization problem is querying the cost function, and not the
              inner machinery of the solver. It is also work in progress: <strong>
                feedback and contributions are welcome</strong>!</p>
            <p><a target="_blank" href="https://github.com/NicolasBoumal/manopt/tree/master/examples">Examples
                are available</a>. </p>
            <p>A short blog post gives an <a target="_blank" href="https://afonsobandeira.wordpress.com/2015/03/16/optimizing-in-smooth-waters-optimization-on-manifolds/">informal
                overview of optimization on manifolds</a>. It may be a good
              start to get a general feeling. There is also a <a target="_blank"
                href="https://www.youtube.com/watch?v=9WTgiqIrgdA">5 minute
                video</a> giving an overview of the general concept.</p>
            <p>It helps us to know our users. If you'd like to, please <a target="_blank"
                href="https://docs.google.com/forms/d/1U9Ntex_rWI8NfCLPP_b8uE5xDnKXgXG-HVvpHdq1PFo/viewform?usp=send_form">follow
                this link to be on our user list</a>. Thanks!</p>
            <h3>Download </h3>
            <p><a target="_blank" class="btn btn-primary" href="download.html">Download
                </a>&#160;&#160; The current version is 5.0 and was packaged on
              Sep. YYY, 2018. The file is about 400 Kb.</p>
            <h3>Install</h3>
            <blockquote>
              <ol>
                <li>Unzip and copy the whole <tt>manopt</tt> directory you just
                  downloaded in a location of your choice, say, in <tt>/my/directory/</tt>.</li>
                <li>Go to <tt>/my/directory/manopt/</tt> at the Matlab prompt
                  and execute <code>importmanopt</code>.</li>
                <li>You may save this path for your next Matlab sessions (via <code>savepath</code>).</li>
              </ol>
            </blockquote>
            <h3>Check</h3>
            <p> Go to <tt>/my/directory/manopt/checkinstall/</tt> and run the
              script <tt>basicexample.m</tt>. If there are no errors, you are
              done! Otherwise, feel free to <a href="#contactmodal">contact us</a>.
            </p>
          </section>
          <section id="firstexample">
            <div class="page-header">
              <h1>A first example</h1>
            </div>
            <h3>The math</h3>
            <p>In this first example, we will compute a dominant eigenvector of
              a symmetric matrix $A \in \mathbb{R}^{n\times n}$. Let $\lambda_1
              \geq \cdots \geq \lambda_n$ be its eigenvalues. The largest
              eigenvalue, $\lambda_1$, <a target="_blank" href="http://en.wikipedia.org/wiki/Rayleigh_quotient"
                rel="tooltip" title="Search for 'Rayleigh quotient' if need be.">is
                known to be</a> the optimal value for the following optimization
              problem:</p>
            <p>$$\max\limits_{x\in\mathbb{R}^n, x \neq 0} \frac{x^T A x}{x^T
              x}.$$</p>
            <p>This can be rewritten as follows:</p>
            <p>$$\min\limits_{x\in\mathbb{R}^n, \|x\| = 1} -x^T A x.$$</p>
            <p>The cost function and its gradient in $\mathbb{R}^n$ read:</p>
            <p>$$<br>
              \begin{align}<br>
              &#160;&#160;&#160; f(x) &amp; = -x^T A x,\\<br>
              &#160;&#160;&#160; \nabla f(x) &amp; = -2Ax.<br>
              \end{align}<br>
              $$</p>
            <p>The constraint on the vector $x$ requires that $x$ be of unit
              2-norm, that is, $x$ is a point on the sphere (one of the nicest
              manifolds):</p>
            <p>$$\mathbb{S}^{n-1} = \{x \in \mathbb{R}^n : x^Tx = 1\}.$$</p>
            <p>This is all the information we need to apply Manopt to our
              problem.</p>
            <p>Users interested in how optimization on manifolds works will be
              interested in the following too: the cost function is smooth on
              $\mathbb{S}^{n-1}$. Its Riemannian gradient on $\mathbb{S}^{n-1}$
              at $x$ is a tangent vector to the sphere at $x$. It can be
              computed as the projection from the usual gradient $\nabla f(x)$
              to that tangent space using the orthogonal projector
              $\mathrm{Proj}_x u = (I-xx^T)u$:</p>
            <p>$$\mathrm{grad}\,f(x) = \mathrm{Proj}_x \nabla f(x) =
              -2(I-xx^T)Ax.$$</p>
            <p>This is an example of a mathematical relationship between the
              Euclidean gradient $\nabla f$, which we often already know how to
              compute from calculus courses, and the Riemannian gradient
              $\mathrm{grad}\,f$, which is needed for the optimization.
              Fortunately, in Manopt the conversion happens behind the scenes
              via a function called <code>egrad2rgrad</code> and we only need
              to compute $\nabla f$. <a href="http://www.matrixcalculus.org/" target="_blank">This
                website</a> can help in figuring out a formula for $\nabla f$.</p>
            <p>We will solve this simple optimization problem using Manopt to
              illustrate the most basic usage of the toolbox. For additional
              theory, see [AMS08], section 4.6.</p>
            <p>[AMS08] P.-A. Absil, R. Mahony and R. Sepulchre, <a target="_blank"
                href="https://press.princeton.edu/absil">Optimization Algorithms
                on Matrix Manifolds</a> (open access), Princeton University
              Press, 2008.</p>
            <h3>The code</h3>
            <p>Solving this optimization problem using Manopt requires little
              Matlab code: </p>
            <!--  pre-scrollable -->
            <pre class="prettyprint lang-matlab linenums">% Generate random problem data.
n = 1000;
A = randn(n);
A = .5*(A+A.');

% Create the problem structure.
manifold = spherefactory(n);
problem.M = manifold;

% Define the problem cost function and its Euclidean gradient.
problem.cost  = @(x) -x'*(A*x);
problem.egrad = @(x) -2*A*x;      % notice the 'e' in 'egrad' for Euclidean

% Numerically check gradient consistency (optional).
checkgradient(problem);

% Solve.
[x, xcost, info, options] = trustregions(problem);

% Display some statistics.
figure;
semilogy([info.iter], [info.gradnorm], '.-');<br>xlabel('Iteration number');<br>ylabel('Norm of the gradient of f');</pre>
            <p>Let us look at the code bit by bit. First, we generate some data
              for our problem and execute these two lines:</p>
            <pre class="prettyprint lang-matlab linenumsoffset linenums:7">manifold = spherefactory(n);
problem.M = manifold;
</pre>
            <p>The call to <a href="https://github.com/NicolasBoumal/manopt/tree/master/manopt/manifolds/sphere"
                target="_blank"><tt>spherefactory</tt></a> returns a structure
              describing the manifold $\mathbb{S}^{n-1}$, i.e., the sphere. This
              manifold corresponds to the constraint appearing in our
              optimization problem. For other constraints, take a look at the <a
                href="#manifolds">various supported manifolds</a>. The second
              instruction creates a structure named <code>problem</code> and
              sets the field <code>problem.M</code> to contain the manifold
              structure. The problem structure will be populated with everything
              a solver could need to know about the problem in order to solve
              it, such as the cost function and its gradient:</p>
            <pre class="prettyprint lang-matlab linenumsoffset linenums:11">problem.cost = @(x) -x'*(A*x);
problem.egrad = @(x) -2*A*x;
</pre>
            <p>The cost function (to be <em>minimized</em>: <strong>Manopt
                always minimizes</strong>) and its derivatives are specified as
              <a target="_blank" href="http://www.mathworks.nl/help/matlab/ref/function_handle.html">function
                handles</a>. Notice how the gradient was specified as the <em>Euclidean</em>
              gradient of $f$, i.e., $\nabla f(x) = -2Ax$ in the function <code>egrad</code>
              (mind the "e"). The conversion to the Riemannian gradient happens
              behind the scene. This is particularly useful when one is working
              with a more complicated manifold.</p>
            <p>An alternative to the definition of the gradient is to specify
              the Riemannian gradient directly, possibly calling Manopt's <code>egrad2rgrad</code>
              conversion tool explicitly:</p>
            <pre class="prettyprint lang-matlab linenumsoffset linenums:12">problem.grad = @(x) manifold.egrad2rgrad(x, -2*A*x);
</pre>
            <p>This is useful if an expression for the Riemannian gradient is
              known for example, and it is natural to use that explicitly. Mind
              the names: <code>problem.grad</code> is to specify the <em>Riemannian</em>
              gradient. If you want to specify the <em>Euclidean</em> gradient,
              the correct name is <code>problem.egrad</code>, with an "e". For
              day to day use, <code>egrad</code> is often the preferred way to
              go.</p>
            <div class="alert alert-info"><strong>Tip!</strong> <a href="http://www.matrixcalculus.org/"
                target="_blank">This website</a> can be helpful in figuring out
              a formula for the Euclidean gradient of your cost function.</div>
            <div class="alert alert-info"><strong>Tip!</strong> Notice that the
              functions <code>cost</code> <emph>and</emph> <code>egrad</code>
              <emph>both</emph> compute the product $Ax$, which is likely to be
              the most expensive operation for large scale problems. This is
              perfectly fine for prototyping, but less so for a final version of
              the implementation. See the many ways of <a href="#costdescription">describing
                the cost function</a> for alternatives that reduce redundant
              computations.</div>
            <div class="alert alert-info"><strong>Tip!</strong> If you do not
              specify the gradient, then Manopt approximates it with finite
              differences. This is slow and can make it difficult to reach
              accurate solutions, hence this feature should only be used for
              quick prototyping on low-dimensional manifolds. As in that case
              the solver may have a hard time reaching points with a small
              gradient, you can pass an options structure to the solver with <code>options.tolgradnorm</code>
              set to a larger value to allow it to stop earlier.</div>
            <p>The next instruction is not needed to solve the problem but often
              helps at the prototyping stage:</p>
            <pre class="prettyprint lang-matlab linenumsoffset linenums:15">checkgradient(problem);
</pre>
            <p>The <a href="https://github.com/NicolasBoumal/manopt/blob/master/manopt/tools/checkgradient.m"
                target="_blank"><tt>checkgradient</tt></a> tool verifies
              numerically that the cost function and its gradient agree up to
              the appropriate order. See the <a href="#tools">tools section</a>
              for more details and more helpful tools offered by Manopt. This
              tool generates the following figure:</p>
            <p style="text-align: center;"><img title="checkgradient figure" alt="checkgradient figure"
                src="tutorial-gradientcheck.png" style="border:0px solid black"
                width="50%"></p>
            <p>The blue curve seems to have the same slope as the dashed line
              over a decent segment (highlighted in orange): that's what we want
              to see (also check the textual output). We now call a solver for
              our problem:</p>
            <pre class="prettyprint lang-matlab linenumsoffset linenums:18">[x, xcost, info, options] = trustregions(problem);
</pre>
            <p>This instruction calls <a href="https://github.com/NicolasBoumal/manopt/blob/master/manopt/solvers/trustregions/trustregions.m"
                target="_blank"><tt>trustregions</tt></a> on our problem,
              without initial guess and without options structure. As a result,
              the solver will generate a random initial guess automatically and
              resort to the default values for all options. As a general feature
              in Manopt, all options are, well, optional. The returned values
              are <code>x</code> (usually an approximate local minimizer of the
              cost function), <code>xcost</code> (the cost value attained by <code>x</code>),
              <code>info</code> (a struct-array containing information about the
              successive iterations performed by the solver) and <code>options</code>
              (a structure containing all options used and their values: take a
              peek to find out what you can parameterize). For more details and
              more solvers, see the <a href="#solvers">solvers</a> section.</p>
            <div class="alert alert-info">This call issues a warning because the
              trust-regions algorithm normally requires the Hessian of the cost
              function, or an approximation of it, to be provided in the problem
              structure. When the Hessian is not provided, Manopt approximates
              it using a finite-differencing scheme on the gradient function and
              warns you about it. You may disable this warning by calling <code>warning('off',
                'manopt:getHessian:approx');</code>. </div>
            <p>Finally, we access the contents of the struct-array <code>info</code>
              to display the convergence plot of our solver: </p>
            <pre class="prettyprint lang-matlab linenumsoffset linenums:22">semilogy([info.iter], [info.gradnorm], '.-');<br>xlabel('Iteration number');<br>ylabel('Norm of the gradient of f');
</pre>
            <p>This generates the following figure:</p>
            <p style="text-align: center;"><img title="Gradient norm converging to zero"
                alt="Gradient norm converging to zero" src="tutorial-gradientnorm.png"
                style="border:0px solid black" width="50%"></p>
            <p>For more information on what data is stored in <code>info</code>,
              see the <a href="#solvers">solvers</a> section.</p>
            <div class="alert alert-info"><strong>Heads up!</strong> Notice that
              we write <code>[info.xxx]</code> and not simply <code>info.xxx</code>,
              because <code>info</code> is a <emph>struct-array</emph>. Read
              this <a target="_blank" href="http://blogs.mathworks.com/loren/2007/04/19/vectorizing-access-to-an-array-of-structures/">MathWorks
                blog post</a> for further information.</div>
          </section>
          <section id="manifolds">
            <div class="page-header">
              <h1>Manifolds </h1>
            </div>
            <h3>General description <img alt="" src="icon_salute.gif" style="vertical-align: baseline"
                width="26"> </h3>
            <p>Manifolds in Manopt are represented as structures and are
              obtained by calling a factory. Built-in factories are located in <tt>/manopt/manifolds</tt>.
              Picking a manifold corresponds to specifying a search space for
              the decision variables. For the special (but common) case of a
              submanifold, the manifold represents a constraint on the decision
              variables (such as the sphere, which constrains vectors to have
              unit norm). In the case of a quotient manifold, the manifold
              captures an invariance in the cost function (such as the Grassmann
              manifold). Typically, points on the manifold as well as tangent
              vectors are represented by matrices, but they could be represented
              by structures, cells, etc. They could even be represented by data
              on a GPU.</p>
            <h3 id="manifoldslibrary">Available manifolds </h3>
            <p>Manopt comes with a number of implementations for generically
              useful manifolds. Of course, manifolds can also be user-defined.
              The best way to build your own is probably to read the code of
              some of the standard factories and to adapt what needs to be
              changed. If you develop an interesting manifold factory and would
              like to share it, be sure to <a href="#contactmodal">let us know</a>:
              we would love to add it to Manopt if it can be of interest to
              other users!</p>
            <!-- table-bordered table-condensed -->
            <table style="width: 100%;" class="table table-striped table-bordered">
              <thead>
                <tr>
                  <td>Name </td>
                  <td>Set </td>
                  <td>Factory</td>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td><a target="_blank" href="reference/manopt/manifolds/euclidean/euclideanfactory.html">Euclidean
                      space</a> (<a href="reference/manopt/manifolds/euclidean/euclideancomplexfactory.html">complex</a>)
                  </td>
                  <td>$\mathbb{R}^{m\times n}$, $\mathbb{C}^{m\times n}$</td>
                  <td><code>euclideanfactory(m, n)</code><br>
                    <code>euclideancomplexfactory(m, n)</code></td>
                </tr>
                <tr>
                  <td><a target="_blank" href="reference/manopt/manifolds/euclidean/symmetricfactory.html">Symmetric
                      matrices</a> </td>
                  <td>$\{ X \in \mathbb{R}^{n\times n} : X = X^T\}^k$ </td>
                  <td><code>symmetricfactory(n, k)</code> </td>
                </tr>
                <tr>
                  <td><a target="_blank" href="reference/manopt/manifolds/euclidean/skewsymmetricfactory.html">Skew-symmetric
                      matrices</a> </td>
                  <td>$\{ X \in \mathbb{R}^{n\times n} : X + X^T = 0\}^k$ </td>
                  <td><code>skewsymmetricfactory(n, k)</code> </td>
                </tr>
                <tr>
                  <td><a target="_blank" href="reference/manopt/manifolds/euclidean/centeredmatrixfactory.html">Centered
                      matrices</a></td>
                  <td>$\{ X \in \mathbb{R}^{m\times n} : X\mathbf{1}_n = 0_m \}$</td>
                  <td><code>centeredmatrixfactory(m, n)</code></td>
                </tr>
                <tr>
                  <td><a href="manifold_documentation_sphere.html">Sphere</a> </td>
                  <td>$\{X\in\mathbb{R}^{n\times m} : \|X\|_\mathrm{F} = 1\}$ </td>
                  <td><code>spherefactory(n, m)</code> </td>
                </tr>
                <tr>
                  <td><a target="_blank" href="reference/manopt/manifolds/sphere/spheresymmetricfactory.html">Symmetric
                      sphere</a></td>
                  <td>$\{X\in\mathbb{R}^{n\times n} : \|X\|_\mathrm{F} = 1, X =
                    X^T\}$ </td>
                  <td><code>spheresymmetricfactory(n)</code></td>
                </tr>
                <tr>
                  <td><a target="_blank" href="reference/manopt/manifolds/sphere/spherecomplexfactory.html">Complex
                      sphere</a> </td>
                  <td>$\{X\in\mathbb{C}^{n\times m} : \|X\|_\mathrm{F} = 1\}$ </td>
                  <td><code>spherecomplexfactory(n, m)</code> </td>
                </tr>
                <tr>
                  <td><a href="manifold_documentation_oblique.html">Oblique
                      manifold</a> </td>
                  <td>$\{X\in\mathbb{R}^{n\times m} : \|X_{:1}\| = \cdots =
                    \|X_{:m}\| = 1\}$ </td>
                  <td><code>obliquefactory(n, m)</code> (To work with
                    $X\in\mathbb{R}^{m \times n}$ with $m$ unit-norm rows
                    instead of columns: <code>obliquefactory(n, m, true)</code>.)</td>
                </tr>
                <tr>
                  <td><a href="reference/manopt/manifolds/oblique/obliquecomplexfactory.html">Complex
                      oblique manifold</a> </td>
                  <td>$\{X\in\mathbb{C}^{n\times m} : \|X_{:1}\| = \cdots =
                    \|X_{:m}\| = 1\}$ </td>
                  <td><code>obliquecomplexfactory(n, m)</code> (To work with
                    unit-norm rows instead of columns: <code>obliquecomplexfactory(n,
                      m, true)</code>.)</td>
                </tr>
                <tr>
                  <td><a target="_blank" href="reference/manopt/manifolds/complexcircle/complexcirclefactory.html">Complex
                      circle</a> </td>
                  <td>$\{z\in\mathbb{C}^n : |z_1| = \cdots = |z_n| = 1\}$ </td>
                  <td><code>complexcirclefactory(n)</code> </td>
                </tr>
                <tr>
                  <td><a target="_blank" href="https://github.com/NicolasBoumal/manopt/blob/master/manopt/manifolds/complexcircle/realphasefactory.m">Phases
                      of real DFT</a></td>
                  <td>$\{z\in\mathbb{C}^n : |z_k| = 1,
                    z_{1+\operatorname{mod}(k, n)} =
                    \bar{z}_{1+\operatorname{mod}(n-k, n)} \ \forall k\}$</td>
                  <td><code>realphasefactory(n)</code></td>
                </tr>
                <tr>
                  <td><a target="_blank" href="reference/manopt/manifolds/stiefel/stiefelfactory.html">Stiefel
                      manifold </a></td>
                  <td>$\{X \in \mathbb{R}^{n \times p} : X^TX = I_p\}^k$ </td>
                  <td><code>stiefelfactory(n, p, k)</code> </td>
                </tr>
                <tr>
                  <td><a target="_blank" href="reference/manopt/manifolds/stiefel/stiefelcomplexfactory.html">Complex
                      Stiefel manifold </a></td>
                  <td>$\{X \in \mathbb{C}^{n \times p} : X^*X = I_p\}^k$ </td>
                  <td><code>stiefelcomplexfactory(n, p, k)</code> </td>
                </tr>
                <tr>
                  <td><a target="_blank" href="reference/manopt/manifolds/stiefel/stiefelgeneralizedfactory.html">Generalized
                      Stiefel manifold </a></td>
                  <td>$\{X \in \mathbb{R}^{n \times p} : X^TBX = I_p\}$ for some
                    $B \succ 0$</td>
                  <td><code>stiefelgeneralizedfactory(n, p, B)</code> </td>
                </tr>
                <tr>
                  <td><a target="_blank" href="reference/manopt/manifolds/stiefel/stiefelstackedfactory.html">Stiefel
                      manifold, stacked </a></td>
                  <td>$\{X \in \mathbb{R}^{md \times k} : (XX^T)_{ii} = I_d\}$ </td>
                  <td><code>stiefelstackedfactory(m, d, k)</code> </td>
                </tr>
                <tr>
                  <td><a target="_blank" href="reference/manopt/manifolds/grassmann/grassmannfactory.html">Grassmann
                      manifold </a></td>
                  <td>$\{\operatorname{span}(X) : X \in \mathbb{R}^{n \times p},
                    X^TX = I_p\}^k$ </td>
                  <td><code>grassmannfactory(n, p, k)</code> </td>
                </tr>
                <tr>
                  <td><a target="_blank" href="reference/manopt/manifolds/grassmann/grassmanncomplexfactory.html">Complex
                      Grassmann manifold </a></td>
                  <td>$\{\operatorname{span}(X) : X \in \mathbb{C}^{n \times p},
                    X^TX = I_p\}^k$ </td>
                  <td><code>grassmanncomplexfactory(n, p, k)</code> </td>
                </tr>
                <tr>
                  <td><a target="_blank" href="reference/manopt/manifolds/grassmann/grassmanngeneralizedfactory.html">Generalized
                      Grassmann manifold </a></td>
                  <td>$\{\operatorname{span}(X) : X \in \mathbb{R}^{n \times p},
                    X^TBX = I_p\}$ for some $B \succ 0$</td>
                  <td><code>grassmannfactory(n, p, B)</code> </td>
                </tr>
                <tr>
                  <td><a href="manifold_documentation_rotations.html">Rotation
                      group</a> </td>
                  <td>$\{R \in \mathbb{R}^{n \times n} : R^TR = I_n, \det(R) =
                    1\}^k$ </td>
                  <td><code>rotationsfactory(n, k)</code> </td>
                </tr>
                <tr>
                  <td><a target="_blank" href="reference/manopt/manifolds/specialeuclidean/specialeuclideanfactory.html">Special
                      Euclidean group</a></td>
                  <td>$\{ (R, t) \in \mathbb{R}^{n \times n} \times \mathbb{R}^n
                    : R^TR = I_n, \det(R) = 1 \}^k$</td>
                  <td><code>specialeuclideanfactory(n, k)</code></td>
                </tr>
                <tr>
                  <td><a target="_blank" href="reference/manopt/manifolds/essential/essentialfactory.html">Essential
                      manifold</a></td>
                  <td>Epipolar constraint between projected points in two
                    perspective views, see <a target="_blank" href="https://fling.seas.upenn.edu/%7Etron">Roberto
                      Tron</a>'s page</td>
                  <td><code>essentialfactory(k, '(un)signed')</code></td>
                </tr>
                <tr>
                  <td>Fixed-rank </td>
                  <td>$\{X \in \mathbb{R}^{m \times n} : \operatorname{rank}(X)
                    = k\}$ </td>
                  <td> <code>fixedrankembeddedfactory(m, n, k)</code> <a target="_blank"
                      href="reference/manopt/manifolds/fixedrank/fixedrankembeddedfactory.html">(ref)</a><br>
                    <code>fixedrankfactory_2factors(m, n, k)</code> <a href="manifold_documentation_fixedrank_2factors.html">(doc)</a><br>
                    <code>fixedrankfactory_2factors_preconditioned(m, n, k)</code>
                    <a target="_blank" href="reference/manopt/manifolds/fixedrank/fixedrankfactory_2factors_preconditioned.html">(ref)</a><br>
                    <code>fixedrankfactory_2factors_subspace_projection(m, n, k)</code>
                    <a target="_blank" href="reference/manopt/manifolds/fixedrank/fixedrankfactory_2factors_subspace_projection.html">(ref)</a><br>
                    <code>fixedrankfactory_3factors(m, n, k)</code> <a target="_blank"
                      href="reference/manopt/manifolds/fixedrank/fixedrankfactory_3factors.html">(ref)</a><br>
                    <code>fixedrankMNquotientfactory(m, n, k)</code> <a target="_blank"
                      href="reference/manopt/manifolds/fixedrank/fixedrankMNquotientfactory.html">(ref)</a></td>
                </tr>
                <tr>
                  <td><a target="_blank" href="reference/manopt/manifolds/fixedranktensors/fixedrankfactory_tucker_preconditioned.html">Fixed-rank
                      tensor</a></td>
                  <td>Tensors of fixed multilinear rank in Tucker format</td>
                  <td><code>fixedrankfactory_tucker_preconditioned</code></td>
                </tr>
                <tr>
                  <td><a target="_blank" href="reference/manopt/manifolds/positive/positivefactory.html">Matrices
                      with strictly positive entries</a></td>
                  <td>$\{ X \in \mathbb{R}^{m\times n} : X_{ij} &gt; 0 \ \forall
                    i, j\}$ </td>
                  <td><code>positivefactory(m, n)</code></td>
                </tr>
                <tr>
                  <td><a target="_blank" href="reference/manopt/manifolds/symfixedrank/sympositivedefinitefactory.html">Symmetric,
                      positive definite matrices</a></td>
                  <td>$\{ X \in \mathbb{R}^{n\times n} : X = X^T, X \succ 0\}^k$
                  </td>
                  <td><code>sympositivedefinitefactory(n)</code></td>
                </tr>
                <tr>
                  <td><a target="_blank" href="manifold_documentation_symfixedrank.html">Symmetric
                      positive semidefinite, fixed-rank</a> (<a target="_blank"
                      href="reference/manopt/manifolds/symfixedrank/symfixedrankYYcomplexfactory.html">complex</a>)</td>
                  <td>$\{X \in \mathbb{R}^{n \times n} : X = X^T \succeq 0,
                    \operatorname{rank}(X) = k\}$ </td>
                  <td><code>symfixedrankYYfactory(n, k)</code><br>
                    <code>symfixedrankYYcomplexfactory(n, k)</code></td>
                </tr>
                <tr>
                  <td><a target="_blank" href="reference/manopt/manifolds/symfixedrank/elliptopefactory.html">Symmetric
                      positive semidefinite, fixed-rank with unit diagonal</a></td>
                  <td>$\{X \in \mathbb{R}^{n \times n} : X = X^T \succeq 0,
                    \operatorname{rank}(X) = k, \operatorname{diag}(X) = 1\}$</td>
                  <td><code>elliptopefactory(n, k)</code></td>
                </tr>
                <tr>
                  <td><a target="_blank" href="reference/manopt/manifolds/symfixedrank/spectrahedronfactory.html">Symmetric
                      positive semidefinite, fixed-rank with unit trace</a></td>
                  <td>$\{X \in \mathbb{R}^{n \times n} : X = X^T \succeq 0,
                    \operatorname{rank}(X) = k, \operatorname{trace}(X) = 1\}$</td>
                  <td><code>spectrahedronfactory(n, k) </code></td>
                </tr>
                <tr>
                  <td><a target="_blank" href="reference/manopt/manifolds/multinomial/multinomialfactory.html">Multinomial
                      manifold</a> (strict simplex elements)</td>
                  <td>$\{ X \in \mathbb{R}^{n\times m} : X_{ij} &gt; 0 \forall
                    i,j \textrm{ and } X^T \mathbf{1}_m = \mathbf{1}_n \}$</td>
                  <td><code>multinomialfactory(n, m)</code></td>
                </tr>
                <tr>
                  <td><a target="_blank" href="manifold_documentation_multinomialdoublystochastic.html">Multinomial
                      doubly stochastic manifold</a></td>
                  <td>$\{ X \in \mathbb{R}^{n\times n} : X_{ij} &gt; 0 \forall
                    i,j \textrm{ and } X \mathbf{1}_n = \mathbf{1}_n, X^T
                    \mathbf{1}_n = \mathbf{1}_n \}$</td>
                  <td><code>multinomialdoublystochasticfactory(n)</code></td>
                </tr>
                <tr>
                  <td><a target="_blank" href="manifold_documentation_multinomialsymmetric.html">Multinomial
                      symmetric and stochastic manifold</a></td>
                  <td>$\{ X \in \mathbb{R}^{n\times n} : X_{ij} &gt; 0 \forall
                    i,j \textrm{ and } X \mathbf{1}_n = \mathbf{1}_n, X = X^T
                    \}$</td>
                  <td><code>multinomialsymmetricfactory(n)</code></td>
                </tr>
                <tr>
                  <td><a target="_blank" href="reference/manopt/manifolds/euclidean/constantfactory.html">Constant
                      manifold (singleton)</a></td>
                  <td>$\{ A \}$</td>
                  <td><code>constantfactory(A)</code></td>
                </tr>
              </tbody>
            </table>
            <p>Bear in mind that a set can often be turned into a Riemannian
              manifold in many different ways, by choosing one or another
              metric. Which metric is best for a specific application may vary.
              This is particularly true for the geometries of the fixed-rank
              matrices. The latter is still a research topic and there is no
              better method yet than experimenting with various geometries.</p>
            <div class="alert alert-info"><strong>Good to know!</strong> Need to
              work on a <emph>product</emph> of manifolds? For example, are you
              minimizing a function $f(X, Y)$ where $X$ has unit norm and $Y$ is
              orthonormal? Or a function $f(X_1, \ldots, X_n)$ where each $X_i$
              lives on a same manifold? Then make sure to check out <code>productmanifold</code>
              and <code>powermanifold</code> in the <a href="#tools">tools
                section</a>. </div>
            <h3>Manifold structure fields</h3>
            <p>A manifold structure has a number of fields, most of which
              contain function handles. Here is a list of things you might find
              in a structure <code>M</code> returned by a manifold factory:</p>
            <table style="width: 100%;" class="table table-striped table-bordered">
              <thead>
                <tr>
                  <td>Name </td>
                  <td>Field usage </td>
                  <td>Functionality </td>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>Name </td>
                  <td><code>M.name()</code> </td>
                  <td>Returns a name for the manifold as a string. </td>
                </tr>
                <tr>
                  <td>Dimension </td>
                  <td><code>M.dim() </code></td>
                  <td>Returns the dimension of the manifold. </td>
                </tr>
                <tr>
                  <td>Metric </td>
                  <td><code>M.inner(x, u, v) </code></td>
                  <td>Computes the Riemannian metric $\langle u, v \rangle_x$. </td>
                </tr>
                <tr>
                  <td>Norm </td>
                  <td><code>M.norm(x, u) </code></td>
                  <td>Computes the Riemannian norm $\|u\|_x = \sqrt{\langle u, u
                    \rangle_x}$.</td>
                </tr>
                <tr>
                  <td>Distance </td>
                  <td><code>M.dist(x, y) </code></td>
                  <td>Computes the Riemannian distance $\operatorname{dist}(x,
                    y)$. </td>
                </tr>
                <tr>
                  <td>Typical distance </td>
                  <td><code>M.typicaldist() </code></td>
                  <td>Returns the "scale" of the manifold. This is used by the
                    trust-regions solver for example, to determine default
                    initial and maximal trust-region radii.</td>
                </tr>
                <tr>
                  <td>Tangent space projector </td>
                  <td><code>M.proj(x, u) </code></td>
                  <td>Computes $\operatorname{Proj}_x u$, the orthogonal
                    projection of the vector $u$ from the ambient or total space
                    to the tangent space at $x$ or to the horizontal space at
                    $x$. </td>
                </tr>
                <tr>
                  <td>Euclidean to Riemannian gradient</td>
                  <td><nobr><code>M.egrad2rgrad(x, egrad)</code></nobr></td>
                  <td>For manifolds embedded in a Euclidean space, converts the
                    gradient of $f$ at $x$ seen as a function in that Euclidean
                    space to the Riemannian gradient of $f$ on the manifold.</td>
                </tr>
                <tr>
                  <td>Euclidean to Riemannian Hessian</td>
                  <td><code>M.ehess2rhess(x, egrad, ehess, u)</code> </td>
                  <td>Similarly to <code>egrad2rgrad</code>, converts the
                    Euclidean gradient and Hessian of $f$ at $x$ along a tangent
                    vector $u$ to the Riemannian Hessian of $f$ at $x$ along $u$
                    on the manifold. </td>
                </tr>
                <tr>
                  <td>Tangentialize</td>
                  <td><code>M.tangent(x, u)</code></td>
                  <td>Re-tangentializes a vector. The input is a vector in the
                    tangent vector representation, which possibly (for example
                    because of error accumulations) is no longer tangent. The
                    output will be the "closest" tangent vector to the input. If
                    tangent vectors are represented in the ambient space, this
                    is equivalent to <code>proj</code>.</td>
                </tr>
                <tr>
                  <td>Tangent to ambient representation</td>
                  <td><code>M.tangent2ambient(x, u)</code></td>
                  <td>Tangent vectors are sometimes represented differently from
                    their counterpart in the ambient space. This function
                    returns the ambient space representation of a tangent vector
                    $u$. Useful when defining the Euclidean Hessian <code>ehess</code>
                    for example. </td>
                </tr>
                <tr>
                  <td>Exponential map </td>
                  <td><code>M.exp(x, u, t) </code></td>
                  <td>Computes $\operatorname{Exp}_x(tu)$, the point you reach
                    by following the vector $u$ scaled by $t$ starting at $x$.
                    As of 5.0, this field should only exist if the manifold
                    provides a genuine exponential map. Otherwise, manually fall
                    back to <code>M.retr</code>.</td>
                </tr>
                <tr>
                  <td>Retraction </td>
                  <td><code>M.retr(x, u, t) </code></td>
                  <td>Computes $\operatorname{Retr}_x(tu)$, where
                    $\operatorname{Retr}$ is a retraction: a cheaper proxy for
                    the exponential map.</td>
                </tr>
                <tr>
                  <td>Logarithmic map </td>
                  <td><code>M.log(x, y) </code></td>
                  <td>Computes $\operatorname{Log}_x(y)$, a tangent vector at
                    $x$ pointing toward $y$. This is meant to be the inverse of
                    $\operatorname{Exp}$.</td>
                </tr>
                <tr>
                  <td>Inverse retraction</td>
                  <td><code>M.invretr(x, y) </code></td>
                  <td>Computes the inverse of the retraction: a tangent vector
                    at $x$ pointing toward $y$. Only few manifolds have this
                    implemented right now.</td>
                </tr>
                <tr>
                  <td>Random point </td>
                  <td><code>M.rand() </code></td>
                  <td>Computes a random point on the manifold. </td>
                </tr>
                <tr>
                  <td>Random vector </td>
                  <td><code>M.randvec(x) </code></td>
                  <td>Computes a random, unit-norm tangent vector in the tangent
                    space at $x$. </td>
                </tr>
                <tr>
                  <td>Zero vector </td>
                  <td><code>M.zerovec(x) </code></td>
                  <td>Returns the zero tangent vector at $x$.</td>
                </tr>
                <tr>
                  <td>Linear combination </td>
                  <td><code>M.lincomb(x, a1, u1, a2, u2) </code></td>
                  <td>Computes the tangent vector at $x$: $v = a_1 u_1 + a_2
                    u_2$, where $a_1, a_2$ are scalars and $u_1, u_2$ are
                    tangent vectors at $x$. The inputs $a_2, u_2$ are optional.
                  </td>
                </tr>
                <tr>
                  <td>Vector transport </td>
                  <td><code>M.transp(x, y, u) </code></td>
                  <td>Computes a tangent vector at $y$ that "looks like" the
                    tangent vector $u$ at $x$. This is not necessarily a
                    parallel transport.</td>
                </tr>
                <tr>
                  <td>Isometric transport</td>
                  <td><code>M.isotransp(x, y, u)</code></td>
                  <td>An isometric vector transport (few manifold
                    implementations offer this, though for some <code>M.transp</code>
                    is isometric: see their documentation).</td>
                </tr>
                <tr>
                  <td>Pair mean </td>
                  <td><code>M.pairmean(x, y) </code></td>
                  <td>Computes the intrinsic mean of $x$ and $y$, that is, a
                    point that lies mid-way between $x$ and $y$ on the geodesic
                    arc joining them. </td>
                </tr>
                <tr>
                  <td>Hashing function </td>
                  <td><code>M.hash(x) </code></td>
                  <td>Computes a string that (almost) uniquely identifies the
                    point $x$ and that can serve as a field name for a
                    structure. (No longer used as of Manopt 2.0.)</td>
                </tr>
                <tr>
                  <td>Vector representation</td>
                  <td><code>M.vec(x, u)</code></td>
                  <td>Returns a <em>real </em>column-vector representation of
                    the tangent vector $u$. The length of the output is always
                    the same and at least <code>M.dim()</code>. This function
                    is linear and invertible on the tangent space at $x$.</td>
                </tr>
                <tr>
                  <td>Normal representation</td>
                  <td><code>M.mat(x, u_vec)</code></td>
                  <td>The inverse of the <code>vec</code> function: returns a
                    tangent vector representation from a column vector such that
                    <code>M.mat(x, M.vec(x, u)) = u</code>. </td>
                </tr>
                <tr>
                  <td>vec and mat isometry check</td>
                  <td><code>M.vecmatareisometries()</code></td>
                  <td>Returns true if <code>M.vec</code> is a linear isometry,
                    i.e., if for all tangent vectors $u,v$, <code>M.inner(x, u,
                      v) == M.vec(x, u).'*M.vec(x, v)</code>. Then, <code>M.mat</code>
                    is both the adjoint and the inverse of <code>M.vec</code>
                    (on the tangent space).</td>
                </tr>
              </tbody>
            </table>
            <p>Not all manifold factories populate all of these fields, but
              that's okay: for many purposes, only a subset of these functions
              are necessary. Notice that it is also very easy to add or replace
              fields in a manifold structure returned by a factory, which can be
              desirable to experiment with various retractions, vector
              transports, etc. If you find ways to improve the built-in
              geometries, <a href="#contactmodal" data-toggle="modal">let us
                know</a>.</p>
          </section>
          <section id="solvers">
            <div class="page-header">
              <h1>Solvers </h1>
            </div>
            <h3>General description <img alt="" src="icon_salute.gif" style="vertical-align: baseline"
                width="26"> </h3>
            <p>Solvers, or optimization algorithms, are functions in Manopt.
              Built-in solvers are located in <span style="font-family: monospace;">/manopt/solvers</span>.
              In principle, all solvers admit the basic call format <code>x =
                mysolver(problem)</code>. The returned value <code>x</code>
              will be a point on the manifold <code>problem.M</code>. Depending
              on the properties of your problem and on the guarantees of the
              solver, <code>x</code> will be more or less close to a good
              minimizer of the cost function described in the <code>problem</code>
              structure. Bear in mind that we are dealing with usually
              nonconvex, and possibly nonsmooth or derivative-free optimization,
              so that it is in general not guaranteed that <code>x</code> will
              be a global minimizer of the cost. For smooth problems with
              gradient information though, most decent algorithms guarantee that
              <code>x</code> will be (approximately) a critical point.
              Typically, we even expect an approximate local minimizer, but even
              that is usually not guaranteed in all cases: this is a fundamental
              limitation of nonlinear optimization). </p>
            <div class="alert alert-info"><strong>Min or max?</strong> All
              provided solvers are <em>minimization</em> algorithms. If you
              want to <em>maximize </em>your objective function, multiply it
              by -1 (and accordingly for the derivatives of the objective
              function if needed), as we did in the <a href="#firstexample">first
                example</a>. </div>
            <p>In principle, all solvers also admit a more complete call format:
              <code>[x, xcost, info, options] = mysolver(problem, x0, options)</code>.
              The output <code>xcost</code> is the value of the cost function
              at the returned point <code>x</code>. The <code>info</code>
              struct-array is described below, and contains information
              collected at each iteration of the solver's progress. The <code>options</code>
              structure is returned too, so you can see what default values the
              solver used on top of the options you (possibly) specified. The
              input <code>x0</code> is an initial guess, or initial iterate,
              for the solver. It is typically a point on the manifold <code>problem.M</code>,
              but may be something else depending on the solver. It can be
              omitted by passing the empty matrix <code>[]</code> instead. The
              <code>options</code> structure is used to fine tune the behavior
              of the optimization algorithm. On top of hosting the algorithmic
              parameters, it manages the stopping criteria as well as what
              information needs to be displayed and / or logged during
              execution. </p>
            <h3>Available solvers </h3>
            <p>The toolbox comes with a handful of solvers. The most
              trust-worthy is the trust-regions algorithm. Originally, it is a
              modification of the code of <a title="GenRTR, by Chris Baker, P.-A. Absil and Kyle Gallivan"
                href="http://www.math.fsu.edu/%7Ecbaker/GenRTR/" target="_blank">GenRTR</a>.
              The toolbox was designed to accommodate many more solvers though:
              we have since then added BFGS-style solvers, stochastic gradient
              descent and more. In particular, we look forward to proposing
              algorithms for nonsmooth cost functions (which notably arise when
              L1 penalties are at play). You can also propose your own solvers.</p>
            <table style="width: 100%;" class="table table-striped table-bordered">
              <thead>
                <tr>
                  <td>Name </td>
                  <td>Requires (benefits of) </td>
                  <td>Comment </td>
                  <td>Call</td>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td><a href="solver_documentation_trustregions.html">Trust-regions
                      (RTR)</a> </td>
                  <td>Cost, gradient (Hessian, approximate Hessian,
                    preconditioner)</td>
                  <td>#1 choice for smooth optimization; uses <abbr title="Finite differences"
                      class="initialism">FD</abbr> of the gradient in the
                    absence of Hessian.</td>
                  <td><code>trustregions(...)</code> </td>
                </tr>
                <tr>
                  <td><a href="reference/manopt/solvers/arc/arc.html">Adaptive
                      regularization by cubics (ARC)</a> </td>
                  <td>Cost, gradient (Hessian, approximate Hessian) </td>
                  <td>Alternative to RTR; uses <abbr title="Finite differences"
                      class="initialism">FD</abbr> of the gradient in the
                    absence of Hessian.</td>
                  <td><code>arc(...)</code> </td>
                </tr>
                <tr>
                  <td><a href="reference/manopt/solvers/steepestdescent/steepestdescent.html">Steepest-descent</a>
                  </td>
                  <td>Cost, gradient </td>
                  <td>Simple implementation of <abbr title="Gradient descent" class="initialism">GD</abbr>
                    ; the built-in line-search is backtracking based. </td>
                  <td><code>steepestdescent(...)</code> </td>
                </tr>
                <tr>
                  <td><a href="reference/manopt/solvers/conjugategradient/conjugategradient.html">Conjugate-gradient
                      </a></td>
                  <td>Cost, gradient (preconditioner) </td>
                  <td>Often performs better than steepest-descent. </td>
                  <td><code>conjugategradient(...)</code> </td>
                </tr>
                <tr>
                  <td><a target="_blank" href="https://github.com/NicolasBoumal/manopt/blob/master/manopt/solvers/barzilaiborwein/barzilaiborwein.m">Barzilai-Borwein</a></td>
                  <td>Cost, gradient</td>
                  <td>Gradient descent with BB step size heuristic.</td>
                  <td><code>barzilaiborwein(...)</code></td>
                </tr>
                <tr>
                  <td><a target="_blank" href="https://github.com/NicolasBoumal/manopt/blob/master/manopt/solvers/bfgs/rlbfgs.m">BFGS<br>
                    </a></td>
                  <td>Cost, gradient</td>
                  <td>Limited-memory version of BFGS.</td>
                  <td><code>rlbfgs(...)</code></td>
                </tr>
                <tr>
                  <td><a target="_blank" href="https://github.com/NicolasBoumal/manopt/blob/master/manopt/solvers/stochasticgradient/stochasticgradient.m">SGD</a></td>
                  <td>Partial gradient (no cost)</td>
                  <td>Stochastic gradient algorithm for optimization of large
                    sums.</td>
                  <td><code>stochasticgradient(...)</code></td>
                </tr>
                <tr>
                  <td><a href="reference/manopt/solvers/pso/pso.html">Particle
                      swarm (PSO) </a></td>
                  <td>Cost </td>
                  <td><abbr title="Derivative-free optimization" class="initialism">DFO</abbr>
                    based on a population of points. </td>
                  <td><code>pso(...)</code> </td>
                </tr>
                <tr>
                  <td><a href="reference/manopt/solvers/neldermead/neldermead.html">Nelder-Mead</a>
                  </td>
                  <td>Cost </td>
                  <td><abbr title="Derivative-free optimization" class="initialism">DFO</abbr>
                    based on a simplex; requires <code>M.pairmean</code>;
                    limited to (very) low-dimensional problems. </td>
                  <td><code>neldermead(...)</code> </td>
                </tr>
              </tbody>
            </table>
            <h3>The options structure </h3>
            <p>In Manopt, <em>all</em> options are optional. Standard options
              are assigned a default value at the toolbox level in <a href="https://github.com/NicolasBoumal/manopt/blob/master/manopt/core/getGlobalDefaults.m"
                target="_blank"><tt>/manopt/core/getGlobalDefaults.m</tt></a>
              (it's a core tool, best not to edit it). Solvers then overwrite
              and complement these options with solver-specific fields. These
              options are in turn overwritten by the user-specified options, if
              any. Here is a list of commonly used options (see each solver's
              documentation for specific information):</p>
            <table style="width: 100%;" class="table table-striped table-bordered">
              <thead>
                <tr>
                  <td>Field name (<code>options."..."</code>) </td>
                  <td>Value type </td>
                  <td>Description </td>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td colspan="3" rowspan="1"><strong>Output and information
                      logging</strong> </td>
                </tr>
                <tr>
                  <td><code>verbosity</code></td>
                  <td>integer </td>
                  <td>Controls how much information a solver outputs during
                    execution; 0: no output; 1 : output at init and at exit; 2:
                    light output at each iteration; more: all you can read. </td>
                </tr>
                <tr>
                  <td><code>debug</code></td>
                  <td>integer </td>
                  <td>If larger than 0, the solver may perform additional
                    computations for debugging purposes. </td>
                </tr>
                <tr>
                  <td><code>statsfun</code> </td>
                  <td>fun. handle </td>
                  <td>
                    <p><a id="statsfunhelp" name="statsfunhelp"></a>If you
                      specify a function handle with prototype <code>stats =
                        statsfun(problem, x, stats)</code>, it will be called
                      after each iteration completes. It receives the <code>problem</code>
                      structure, the current point <code>x</code> and the
                      statistics structure <code>stats</code> that will be
                      logged in the <code>info</code> struct-array at the
                      corresponding iteration number. This function gives you a
                      chance to modify the <code>stats</code> structure, hence
                      to add fields if you want to. Bear in mind that structures
                      in a struct-array must <em>all </em>have the same
                      fields, so that if <code>statsfun</code> adds a field to
                      a <code>stats</code> structure, it must do so for <em>all
                        </em>iterations. Time spent in <code>statsfun</code> is
                      discounted from execution time, as this is typically only
                      used for prototyping / debugging.</p>
                    <p>Example:</p>
                    <pre class="prettyprint lang-matlab linenums">options.statsfun = @mystatsfun;
function stats = mystatsfun(problem, x, stats)
    stats.current_point = x;
end</pre>
                    <p> This will log all the points visited during the
                      optimization process in the <code>info</code>
                      struct-array returned by the solver. One could also write
                      <code>x</code> to disk during this call (if that is
                      useful).</p>
                    <p>You may also provide a function handle with this calling
                      pattern: <code>stats = statsfun(problem, x, stats, store)</code>.
                      This additionally lets you access the data stored for that
                      particular iterate in the store structure. As of Manopt
                      1.0.8, this memory has an additional field: <code>store.shared</code>
                      (it can be read, but not edited here). This field contains
                      "permanent" memory, shared by all points <code>x</code>
                      visited so far.</p>
                    <p>An alternative is to use the <tt><a href="https://github.com/NicolasBoumal/manopt/blob/master/manopt/tools/statsfunhelper.m"
                          target="_blank">statsfunhelper</a></tt> tool, which is
                      sometimes simpler (and allows to pass inline functions).
                      The example above simplifies to:</p>
                    <pre class="prettyprint lang-matlab linenums">options.statsfun = statsfunhelper('current_point', @(x) x);</pre>
                    <p>The helper can also be used to log more than one metric,
                      by passing it a structure. In the example below, <code>x_reference</code>
                      is a certain point on the manifold <code>problem.M</code>.
                      The stats structures will include fields <code>current_point</code>
                      and <code>dist_to_ref</code>. Notice how the function
                      handles can take different inputs. See the help of that
                      tool for more info.</p>
                    <pre class="prettyprint lang-matlab linenums">metrics.current_point = @(x) x;<br>metrics.dist_to_ref = @(problem, x) problem.M.dist(x, x_reference);<br>options.statsfun = statsfunhelper(metrics);</pre>
                    <p>See also the example on <a href="https://github.com/NicolasBoumal/manopt/blob/master/examples/using_counters.m"
                        target="_blank">how to use Manopt counters</a> to keep
                      track of things such as cost / gradient / Hessian calls or
                      other special operations such as matrix-vector products.
                      These counters are registered at every iteration and
                      available in the returned stats structure. They can also
                      be used as stopping criterion.</p>
                  </td>
                </tr>
                <tr>
                  <td colspan="3" rowspan="1"><strong>Stopping criteria</strong>
                  </td>
                </tr>
                <tr>
                  <td><code>maxiter</code></td>
                  <td>integer </td>
                  <td>Limits the number of iterations of the solver. </td>
                </tr>
                <tr>
                  <td><code>maxtime</code></td>
                  <td>double </td>
                  <td>Limits the <abbr title="Not taking into account time spent in statsfun.">execution
                      time</abbr> of the solver, in seconds. </td>
                </tr>
                <tr>
                  <td><code>tolcost</code></td>
                  <td>double </td>
                  <td>Stop as soon as the cost drops below this tolerance. </td>
                </tr>
                <tr>
                  <td><code>tolgradnorm</code></td>
                  <td>double </td>
                  <td>Stop as soon as the norm of the gradient drops below this
                    tolerance. </td>
                </tr>
                <tr>
                  <td><code>stopfun</code> </td>
                  <td>fun. handle </td>
                  <td>
                    <p>If you specify a function handle with prototype <code>stopnow
                        = stopfun(problem, x, info, last)</code>, it will be
                      called after each iteration completes with the <code>problem</code>
                      structure, the current point <code>x</code> , the whole <code>info</code>
                      struct-array built so far and an index <code>last</code>
                      such that <code>info(last)</code> is the structure
                      pertaining to the current iteration (this is because <code>info</code>
                      is pre-allocated, so that <code>info(end)</code>
                      typically does <em>not</em> refer to the current
                      iteration). The return value is a Boolean. If <code>stopnow</code>
                      is returned as <tt>true</tt>, the solver will terminate.</p>
                    <p>Example:</p>
                    <pre class="prettyprint lang-matlab linenums">options.stopfun = @mystopfun;
function stopnow = mystopfun(problem, x, info, last)
    stopnow = (last &gt;= 3 &amp;&amp; info(last-2).cost - info(last).cost &lt; 1e-3);
end</pre>
                    <p> This will tell the solver to exit as soon as two
                      successive iterations combined have decreased the cost by
                      less than 10<sup>-3</sup>. it is also possible to return a
                      second output, <code>reason</code>: a string that will be
                      displayed (if <code>options.verbosity</code> is large
                      enough) to inform the user of why the solver stopped (if
                      it did because of this criterion).</p>
                    <p>See also the two interactive stopping criteria: by <a href="https://github.com/NicolasBoumal/manopt/blob/master/manopt/tools/stopifclosedfigure.m"
                        target="_blank">closing a figure</a>, and by <a href="https://github.com/NicolasBoumal/manopt/blob/master/manopt/tools/stopifdeletedfile.m"
                        target="_blank">deleting a file</a>. This allows to
                      gracefully interrupt a solver when it takes too much time.</p>
                    <p>See also the example on <a href="https://github.com/NicolasBoumal/manopt/blob/master/examples/using_counters.m"
                        target="_blank">how to use Manopt counters in a stopping
                        criterion</a>, which makes it easy to stop after a
                      certain budget of function calls, matrix-vector products
                      etc. has been exceeded.</p>
                  </td>
                </tr>
                <tr>
                  <td colspan="3" rowspan="1"><strong>Line-search<a id="linesearchoptions">&#160;</a></strong>
                  </td>
                </tr>
                <tr>
                  <td><code>linesearch</code></td>
                  <td>fun. handle</td>
                  <td>
                    <p>Some solvers, such as <code>steepestdescent</code> and <code>conjugategradient</code>,
                      need to solve a line-search problem at each iteration.
                      That is, they need to (approximately) solve the
                      one-dimensional optimization problem:<br>
                      $$\min_{t\geq 0} \phi(t) = f(\operatorname{Retr}_x(td)),$$<br>
                      where $x$ is the current point on the manifold, $d$ is a
                      tangent vector at $x$ (the search direction),
                      $\operatorname{Retr}$ is the retraction on the manifold
                      and $f$ is the cost function. Assuming $d$ is a descent
                      direction, there exists $t &gt; 0$ such that $\phi(t) &lt;
                      \phi(0) = f(x)$. The purpose of a line-search algorithm is
                      to find such a real number $t$.</p>
                    <p>Manopt includes certain <a href="https://github.com/NicolasBoumal/manopt/tree/master/manopt/solvers/linesearch"
                        target="_blank">generic purpose line-search algorithms</a>.
                      To force the use of one of them or of your own, specify
                      this in the options structure (not in the problem
                      structure) as follows: <code>options.linesearch =
                        @linesearch_adaptive;</code> (for example). Each
                      line-search algorithm accepts its own options which can be
                      added in this same <code>options</code> structure passed
                      to the master solver. See each line-search's help for
                      details.</p>
                    <p>For certain problems, you may want to implement your own
                      line-search, typically in order to exploit structure
                      specific to the problem at hand. To this end, it is best
                      to start from an existing line-search function and to
                      adapt it. Alternatively (and perhaps more easily), you may
                      specify a <code>linesearch</code> function in the <code>problem</code>
                      structure (see the <a href="#linesearchproblem">cost
                        description section</a>) and use a line-search that will
                      use it, to incorporate the additional information you
                      supply there. Do not hesitate to ask for help on the forum
                      if you run into trouble here :).</p>
                  </td>
                </tr>
                <tr>
                  <td colspan="3" rowspan="1"><strong>Miscellaneous</strong> </td>
                </tr>
                <tr>
                  <td><code>storedepth</code></td>
                  <td>integer </td>
                  <td>Maximum number of <code>store</code> structures that may
                    be kept in memory (see the <a href="#costdescription">cost
                      description</a> section). As of Manopt 5.0, this is mostly
                    irrelevant because main solvers do a much better job of
                    discarding stale information on the go.</td>
                </tr>
              </tbody>
            </table>
            <p>Keep in mind that a specific solver may not use all of these
              options and may use additional options, which would then be
              described on the solver's documentation page or, more commonly, in
              the help section of the solver's code (e.g.: <code>help
                trustregions</code>). </p>
            <div class="alert alert-info"><strong>Good to know!</strong> Need a
              problem-specific stopping criterion? Include a <code>stopfun</code>
              in your <code>options</code> structure. See above for details.</div>
            <h3>The info struct-array </h3>
            <p>The various solvers log information at each iteration about their
              progress. This information is returned in the output <code>info</code>,
              a struct-array, that is, an array of structures. Read this <a href="http://blogs.mathworks.com/loren/2007/04/19/vectorizing-access-to-an-array-of-structures/"
                target="_blank">MathWorks blog post</a> for help on dealing with
              this data container in Matlab. For example, to extract a vector
              containing the cost value at each iteration, call <code>[info.cost]</code>
              <em> with the brackets</em>. Here are the typical indicators that
              might be present in the <code>info</code> output:</p>
            <table style="width: 100%;" class="table table-striped table-bordered">
              <thead>
                <tr>
                  <td>Field name (<code>[info."..."]</code>) </td>
                  <td>Value type </td>
                  <td>Description </td>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td><code>iter</code></td>
                  <td>integer </td>
                  <td>Iteration number (0 corresponds to the initial guess). </td>
                </tr>
                <tr>
                  <td><code>time</code> </td>
                  <td>double </td>
                  <td>Elapsed <abbr title="Not taking into account time spent in statsfun.">execution
                      time</abbr> until completion of the iterate, in seconds. </td>
                </tr>
                <tr>
                  <td><code>cost</code> </td>
                  <td>double </td>
                  <td>Attained value of the cost function. </td>
                </tr>
                <tr>
                  <td><code>gradnorm</code> </td>
                  <td>double </td>
                  <td>Attained value for the norm of the gradient. </td>
                </tr>
              </tbody>
            </table>
            <p>A specific solver may not populate all of these fields and may
              provide additional fields, which would then be described in the
              solver's documentation. </p>
            <div class="alert alert-info"><strong>Good to know!</strong> Need to
              log problem-specific information at each iteration? Include a <code>statsfun</code>
              in your <code>options</code> structure. See above for details.
              See also an example on <a href="https://github.com/NicolasBoumal/manopt/blob/master/examples/using_counters.m"
                target="_blank">Manopt counters</a> to keep track of things such
              as function calls, Hessian calls, etc.</div>
            <div class="alert alert-info"><strong>Heads up!</strong> The
              execution time is logged <em>without</em> incorporating time
              spent in <code>statsfun</code>, as it usually performs
              computations that are not needed to solve the optimization
              problem. If, however, you use information logged by <code>statsfun</code>
              for your <code>stopfun</code> criterion, and if this is important
              for your method (i.e., it is not just for convenience during
              prototyping), you should time the execution time of <code>statsfun</code>
              and add it to the <code>stats.time</code> field. </div>
          </section>
          <section id="costdescription">
            <div class="page-header">
              <h1>Describing the cost function</h1>
            </div>
            <h3>General philosophy <img alt="" src="icon_salute.gif" style="vertical-align: baseline"
                width="26"></h3>
            <p>An optimization problem in Manopt is represented as a <code>problem</code>
              structure. The latter must include a field <code>problem.M</code>
              which contains a structure describing a manifold, as obtained from
              <a href="#manifolds">a factory</a>. On top of this, the problem
              structure must include some fields that describe the cost function
              $f$ to be minimized and, possibly, its derivatives. </p>
            <p>The solvers do <em>not </em>query these function handles
              directly. Instead, they call core (internal) tools such as <code>getCost</code>,
              <code>getGradient</code>, <code>getHessian</code>, etc. These
              tools consider the available fields in the problem structure and
              "do their best" to return the required object. </p>
            <p>As a result, we gain great flexibility in the cost function
              description. Indeed, as the needs grow during the life-cycle of
              the toolbox and new ways of describing the cost function become
              necessary, it suffices to update the core <code>get*</code> tools
              to take these new ways into account. This has also made it much
              easier over time to incorporate (and improve) caching. We seldom
              have to modify the solvers.</p>
            <h3>Cost describing fields</h3>
            <p> You may specify as many of the following fields as you wish in
              the <code>problem</code> structure. If you specify some function
              more than once (for example, if you define <code>diff</code> <em>and</em>
              <code>grad</code>, both of which could be used to compute
              directional derivatives), the toolbox does not specify which will
              be called (hence, it is better not to, or to be really sure about
              consistency). Probably, the toolbox would assume the code for <code>diff</code>
              is more efficient than the code for <code>grad</code> when only a
              directional derivative is needed, but there is no guarantee.
              Bottom line: they should be consistent (profile if need be).</p>
            <p>In the table below, each function admits three different calling
              patterns. The first one is the simplest and is perfectly fine for
              prototyping. The other calling patterns give explicit access to
              Manopt's caching system, which is documented below.</p>
            <div class="alert alert-info"><strong>Good to know!</strong> All
              function handles admit a store structure as extra argument for
              caching purposes, as explained in the next section. This is an
              optional feature. For prototyping, it is often easier to write a
              first version of the code without caching. In any case, Manopt
              includes some automatic caching.</div>
            <table style="width: 100%;" class="table table-striped table-bordered">
              <thead>
                <tr>
                  <td>Field name (<code>problem."..."</code>)</td>
                  <td>Prototype </td>
                  <td>Description </td>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td><code>cost</code> </td>
                  <td><code>f = cost(x)</code><br>
                    <nobr><code>[f, store] = cost(x, store)</code></nobr><br>
                    <nobr><code>f = cost(x, storedb, key)</code></nobr></td>
                  <td>$f = f(x)$ </td>
                </tr>
                <tr>
                  <td><code>grad</code> </td>
                  <td><code>g = grad(x)</code><br>
                    <nobr><code>[g, store] = grad(x, store)</code></nobr><br>
                    <nobr><code>g = grad(x, storedb, key)</code></nobr></td>
                  <td>$g = \operatorname{grad} f(x)$ </td>
                </tr>
                <tr>
                  <td><code>costgrad</code> </td>
                  <td><code>[f, g] = costgrad(x)</code><br>
                    <nobr><code>[f, g, store] = costgrad(x, store)</code></nobr><br>
                    <nobr><code>[f, g] = costgrad(x, storedb, key)</code></nobr>
                  </td>
                  <td>Computes both $f = f(x)$ and $g = \operatorname{grad}
                    f(x)$.</td>
                </tr>
                <tr>
                  <td><code>egrad</code> </td>
                  <td><code>eg = egrad(x)</code><br>
                    <nobr><code>[eg, store] = egrad(x, store)</code></nobr><br>
                    <nobr><code>eg = egrad(x, storedb, key)</code></nobr> </td>
                  <td>
                    <p>For submanifolds of a Euclidean space or quotient spaces
                      with a Euclidean total space, computes $eg = \nabla f(x)$,
                      the gradient of $f$ "as if" it were defined in that
                      Euclidean space. This will be passed to <code>M.egrad2rgrad</code>.</p>
                    <p>Function <code>egrad</code> involves automatic caching
                      for use with <code>ehess</code>.</p>
                  </td>
                </tr>
                <tr>
                  <td><code>partialgrad</code> </td>
                  <td><code>pg = partialgrad(x, I)</code><br>
                    <nobr><code>[pg, store] = partialgrad(x, I, store)</code></nobr><br>
                    <nobr><code>pg = partialgrad(x, I, storedb, key)</code></nobr>
                  </td>
                  <td>
                    <p>Assume the cost function <code>problem.cost</code> is a
                      sum of many terms, as $f(x) = \sum_{i=1}^{d} f_i(x)$ where
                      $d$ is specified as <code>problem.ncostterms = d</code>.
                      For a subset $I$ of $1\ldots d$, <code>partialgrad(x, I)</code>
                      returns the Riemannian gradient of the partial cost
                      function $f_I(x) = \sum_{i \in I} f_i(x)$. </p>
                  </td>
                </tr>
                <tr>
                  <td><code>partialegrad</code> </td>
                  <td><code>peg = partialegrad(x, I)</code><br>
                    <nobr><code>[peg, store] = partialegrad(x, I, store)</code></nobr><br>
                    <nobr><code>peg = partialegrad(x, I, storedb, key)</code></nobr>
                  </td>
                  <td>
                    <p>Same as <code>partialgrad</code> but returns the
                      Euclidean partial gradient. This will automatially be
                      transformed into a Riemannian partial gradient by Manopt.
                    </p>
                  </td>
                </tr>
                <tr>
                  <td><code>approxgrad</code> </td>
                  <td><code>g = approxgrad(x)</code><br>
                    <nobr><code>[g, store] = approxgrad(x, store)</code></nobr><br>
                    <nobr><code>g = approxgrad(x, storedb, key)</code></nobr> </td>
                  <td>
                    <p>Approximation for the gradient of the cost at $x$.
                      Solvers asking for the gradient when one is not provided
                      will automatically fall back to this approximation. If it
                      is not provided either, a standard finite-difference
                      approximation of the gradient based on the cost is
                      built-in.</p>
                    <p>This is slow because it involves generatin an orthonormal
                      basis of the tangent space at $x$ and computing a finite
                      difference of the cost along each basis vector. This is
                      useful almost exclusively for prototyping. Because of the
                      limited accuracy, it may be necessary to increase <code>options.tolgradnorm</code>
                      when using this feature.</p>
                    <p>See <a style="font-family: monospace;" href="reference/manopt/solvers/gradientapproximations/index.html">/solvers/gradientapproximations</a>.</p>
                  </td>
                </tr>
                <tr>
                  <td><code>subgrad</code></td>
                  <td><code>g = subgrad(x, tol)</code><br>
                    <code>[g, store] = subgrad(x, tol, store)</code><br>
                    <code>g = subgrad(x, tol, storedb, key)</code></td>
                  <td>Returns a Riemannian subgradient of the cost function at
                    $x$, with a tolerance <code>tol</code> which is a
                    nonnegative real number. If you wish to return the minimal
                    norm subgradient (which may help solvers), see the <a target="_blank"
                      href="https://github.com/NicolasBoumal/manopt/blob/master/manopt/tools/smallestinconvexhull.m">smallestinconvexhull</a>
                    tool.</td>
                </tr>
                <tr>
                  <td><code>diff</code> </td>
                  <td><code>d = diff(x, u)</code><br>
                    <nobr><code>[d, store] = diff(x, u, store)</code></nobr><br>
                    <nobr><code>d = diff(x, u, storedb, key)</code></nobr></td>
                  <td>$d = \operatorname{D}\! f(x)[u]$ defines directional
                    derivatives. If the gradient exists, it can be computed from
                    this (slowly.)</td>
                </tr>
                <tr>
                  <td><code>hess</code> </td>
                  <td><code>h = hess(x, u)</code><br>
                    <nobr><code>[h, store] = hess(x, u, store)</code></nobr><br>
                    <nobr><code>h = hess(x, u, storedb, key)</code></nobr></td>
                  <td>$h = \operatorname{Hess} f(x)[u]$, where $u$ represents a
                    tangent vector. </td>
                </tr>
                <tr>
                  <td><code>ehess</code> </td>
                  <td><code>eh = ehess(x, u)</code><br>
                    <nobr><code>[eh, store] = ehess(x, u, store)</code></nobr><br>
                    <nobr><code>eh = ehess(x, u, storedb, key)</code></nobr></td>
                  <td>
                    <p>For submanifolds of a Euclidean space, or for quotient
                      spaces with a Euclidean total space, this computes $eh =
                      \nabla^2 f(x)[u]$: the Hessian of $f$ along $u$ "as if" it
                      were defined in that Euclidean space. This is passed to <code>M.ehess2rhess</code>
                      and thus requires the Euclidean gradient to be accessible
                      (<code>egrad</code>). Input $u$ is a representation of the
                      tangent vector. For most manifolds, this is a vector in
                      the ambient space. In general, you may need to call <code>M.tangent2ambient(x,
                        u)</code> to obtain the ambient space equivalent of $u$.
                      This is the case for <code>rotationsfactory</code> for
                      example. The output <code>eh</code> should be a vector in
                      the ambient space.</p>
                    <p>Function <code>egrad</code> involves automatic caching
                      for use with <code>ehess</code>.</p>
                  </td>
                </tr>
                <tr>
                  <td><code>approxhess</code> </td>
                  <td><code>h = approxhess(x, u)</code><br>
                    <nobr><code>[h, store] = approxhess(x, u, store)</code></nobr><br>
                    <nobr><code>h = approxhess(x, u, storedb, key)</code></nobr>
                  </td>
                  <td>
                    <p>This can be any mapping from the tangent space at $x$ to
                      itself. Often, one would like for it to be a linear,
                      symmetric operator. Solvers asking for the Hessian when
                      one is not provided will automatically fall back to this
                      approximate Hessian. If it is not provided either, a
                      standard finite-difference approximation of the Hessian
                      based on the gradient is built-in.</p>
                    <p>See <a style="font-family: monospace;" href="reference/manopt/solvers/hessianapproximations/index.html">/solvers/hessianapproximations</a>.</p>
                  </td>
                </tr>
                <tr>
                  <td><code>precon</code> </td>
                  <td><code>v = precon(x, u)</code><br>
                    <nobr><code>[v, store] = precon(x, u, store)</code></nobr><br>
                    <nobr><code>v = precon(x, u, storedb, key)</code></nobr> </td>
                  <td>
                    <p>$v = \operatorname{Prec}(x)[u]$, where
                      $\operatorname{Prec}(x)$ is a preconditioner for the
                      Hessian $\operatorname{Hess} f(x)$, that is,
                      $\operatorname{Prec}(x)$ is a symmetric, positive-definite
                      linear operator (w.r.t. the Riemannian metric) on the
                      tangent space at $x$. Ideally, it is cheap to compute and
                      such that solving a linear system in
                      $\operatorname{Prec}^{1/2}(x) \circ \operatorname{Hess}
                      f(x) \circ \operatorname{Prec}^{1/2}(x)$ is easier than
                      without the preconditioner, i.e., it should approximate
                      the inverse of the Hessian.</p>
                    <p>See <a style="font-family: monospace;" href="reference/manopt/solvers/preconditioners/index.html">/solvers/preconditioners</a>.</p>
                  </td>
                </tr>
                <tr>
                  <td><code>sqrtprecon</code> </td>
                  <td><code>v = sqrtprecon(x, u)</code><br>
                    <nobr><code>[v, store] = sqrtprecon(x, u, store)</code></nobr><br>
                    <nobr><code>v = sqrtprecon(x, u, storedb, key)</code></nobr>
                  </td>
                  <td>$v = \operatorname{Prec}^{1/2}(x)[u]$, where
                    $\operatorname{Prec}^{1/2}(x)$ is an (operator) square root
                    of a preconditioner for the Hessian $\operatorname{Hess}
                    f(x)$, that is, $\operatorname{Prec}^{1/2}(x)$ is a
                    symmetric, positive-definite linear operator (w.r.t. the
                    Riemannian metric) on the tangent space at $x$, and applying
                    it twice should amount to applying $\operatorname{Prec}(x)$
                    once. Solvers typically use <code>precon</code> rather than
                    <code>sqrtprecon</code>, but some tools (such as <a style="font-family: monospace;"
                      href="reference/manopt/tools/hessianspectrum.html">hessianspectrum</a>)
                    can use <code>sqrtprecon</code> to speed up computations.</td>
                </tr>
                <tr>
                  <td><code>linesearch</code><a id="linesearchproblem"> </a></td>
                  <td><code>t = linesearch(x, u)</code><br>
                    <code>[t, store] = linesearch(x, u, store)</code><br>
                    <code>t = linesearch(x, u, storedb, key)</code></td>
                  <td>
                    <p>Given a point $x$ and a tangent vector $u$ at $x$, assume
                      $u$ is a descent direction. This means there exists $t
                      &gt; 0$ such that $\phi(t) &lt; \phi(0)$ with<br>
                      $$\phi(t) = f(\operatorname{Retr}_x(td)).$$<br>
                      Line-search algorithms, which are used by some solvers
                      such as <code>steepestdescent</code> and <code>conjugategradient</code>,
                      are designed to (approximately) minimize $\phi$ at each
                      iteration.</p>
                    <p>There are built-in, generic ways of doing this. If you
                      have additional structure in your problem that enables you
                      to take a good guess at what $t$ should be, than you can
                      specify it here, in this function handle. This (very much
                      optional) function should return a positive $t &gt; 0$
                      such that $t$ is a good guess of where to look for a
                      minimizer of $\phi$. The line-search algorithm (if it
                      decides to use this information) will start by looking at
                      the step $td$, and decide to accept it or not based on its
                      internal rules. See the <code>linesearch</code> <a href="#linesearchoptions">option
                        in the solver section</a> (options table) for details on
                      available line-search algorithms and how to pick one.<br>
                      <br>
                      See <span style="font-family: monospace;"><a href="https://github.com/NicolasBoumal/manopt/blob/master/examples/low_rank_matrix_completion.m"
                          target="_blank">low_rank_matrix_completion</a></span>
                      for an example from the literature.</p>
                  </td>
                </tr>
              </tbody>
            </table>
            <div class="alert alert-info"><strong>Heads up!</strong> StoreDB is
              a <a target="_blank" href="http://fr.mathworks.com/help/matlab/matlab_oop/comparing-handle-and-value-classes.html">handle
                class</a>, which means its instances are passed by reference.
              This means when a storedb object is passed as input to a function,
              and that function modifies the storedb object, the calling
              function will see the changes too (without the need to explicitly
              return the storedb object). Thus, each storedb object exists only
              <em>once</em> in memory. This makes for cleaner calling patterns
              and avoids unnecessary copies. This is not the case for the store
              structures though, which are passed by copy and thus must be
              returned if the changes are to be permanent.</div>
            <p> Here is one way to address the redundant computation of $Ax$
              that appeared in the <a href="file:///C:/Users/nicolas/manopt/web/tutorial.html#firstexample">first
                example</a>. Replace the cost and gradient description (code
              lines 11-12) with the following code (we chose to spell out the
              gradient projection, but that is not necessary: you could also use
              <code>M.egrad2rgrad</code>).</p>
            <pre class="prettyprint lang-matlab linenums">problem.costgrad = @(x) mycostgrad(A, x);
function [f, g] = mycostgrad(A, x)
    Ax = A*x;
    f = -x'*Ax;
    if nargout == 2
        g = -2*(Ax + f*x);   % or: g = M.egrad2rgrad(x, -2*Ax);
    end
end
</pre>
            <p>Solvers that call subsequently for the cost and the gradient at
              the same point will be able to escape most redundant computations
              (e.g., <code>steepestdescent</code> and <code>conjugategradient</code>
              are good at this). This is not perfect though: when the Hessian is
              requested for example, we can't access our hard work (<code>trustregions</code>
              would not gain much for example). In the next section, we cover a
              more sophisticated way of sharing data between components of the
              cost description. </p>
            <h3><a id="cachingsystem" name="cachingsystem"></a>Caching: how to
              use the store structure </h3>
            <p>As demonstrated in the <a href="#firstexample">first example</a>,
              it is often the case that computing $f(x)$ produces intermediate
              results (such as the product $Ax$) that can be reused in order to
              compute $\operatorname{grad} f(x)$. More generally, computing
              anything at a point $x$ may produce intermediate results that
              could be reused for other computations at $x$. Furthermore, it may
              happen that a solver will call cost-related functions more than
              once at the same point $x$. For those cases, it may be beneficial
              to cache (to store) some of the previously computed objects, or
              intermediate calculations.</p>
            <p>For that purpose, Manopt manages a database of <code>store</code>
              structures, with a class called <a href="reference/manopt/core/StoreDB.html"><span
                  style="font-family: monospace;">StoreDB</span></a>. For each
              visited point $x$, a <code>store</code> structure is stored in
              the database. Only the structures pertaining to the most recently
              used points are kept in memory (see the <code>options.storedepth</code>
              <a href="#solvers">option</a>). StoreDB manages a counter to
              number visited points on the manifold. This way, each point $x$
              receives a unique <code>key</code>. This key can be used to
              interact with the store associated to $x$.</p>
            <p>Whenever a solver calls, say, the <code>cost</code> function at
              some point $x$, the toolbox will search for a <code>store</code>
              structure pertaining to that $x$ in the database (using its key).
              If there is one and if <code>problem.cost</code> (for example)
              admits <code>store</code> as an input and as an output, the <code>store</code>
              is passed to the <code>cost</code> function. The <code>cost</code>
              function then performs its duty and gets to modify the <code>store</code>
              structure at will: it is <em>your </em>structure, do whatever
              you fancy with it. Next time a function is called at the <em>same</em>
              point $x$ (say, <code>problem.grad</code>), the <em>same</em> <code>store</code>
              structure will be passed along, modified, and stored again. As
              soon as the solver goes on to explore a new point $x'$, a <em>different</em>
              <code>store</code> structure is created and maintained in the same
              way. If the solver then decides to return to the previous $x$ (and
              <code>options.storedepth</code> is larger than 2), we will still
              benefit from the previously stored work as the previous <code>store</code>
              structure will still be available.</p>
            <p>As of Manopt 5.0, by default, the cost value $f(x)$ is cached at
              every visited point (for as long as the memory associated to that
              point is retained.) This means that calling <code>getCost(problem,
                x, storedb, key)</code> multiple times with the same inputs will
              only actually call the cost function the first time. In practice,
              this provides good speed-ups for line-search algorithms.
              Similarly, the gradient and Euclidean gradient are cached by
              default, which provides speed-ups for a number of solvers. This is
              made practical by the new store managment system that allows
              solvers to more quickly discard irrelevant stores, thus minimizing
              memory usage.</p>
            <p> As of Manopt 1.0.8, the store structure also includes a field <code>store.shared</code>.
              The contents of that field are shared among all visited points
              $x$. This memory is also readable from <code>options.statsfun</code>
              (see <a href="#statsfunhelp">statsfun</a> documentation and the <a
                href="https://github.com/NicolasBoumal/manopt/blob/master/examples/maxcut.m"
                target="_blank">maxcut example</a>). (Note: this mechanism was
              originally used to keep track of function calls; as of Manopt 5.0,
              it is much better to use <a href="https://github.com/NicolasBoumal/manopt/blob/master/examples/using_counters.m"
                target="_blank">Manopt counters</a>.) </p>
            <p>The information in this paragraph is aimed at solver developers;
              it may also help users understand what happens under the hood:
              When given access to <code>storedb</code> and a <code>key</code>
              associated to $x$ rather than to a specific store, the store of
              $x$ can be obtained as <code>store = storedb.getStore(key)</code>.
              Put the modified store back in the database with <code>storedb.set(store,
                key)</code>. Access the shared memory directly as <code>storedb.shared</code>,
              <em>not </em>via <code>store.shared</code>. This is important: <code>store</code>
              might have a <code>store.shared</code> field, but when <code>storedb</code>
              and <code>key</code> are explicitly used, <code>store.shared</code>
              will not be populated or read on get/set. Each point $x$ should be
              associated to a key, which is obtained by calling <code>storedb.getNewKey()</code>.
              From time to time, call <code>storedb.purge()</code> to reduce
              memory usage. Even better, as soon as you know that the store
              associated to a certain point is no longer useful, call <code>storedb.remove(key)</code>
              or <code>storedb.removefirstifdifferent(key1, key2)</code>.</p>
            <p>Here is an example of how we can modify the <a href="#firstexample">first
                example</a> to avoid redundant computations, using the caching
              mechanism:</p>
            <pre class="prettyprint lang-matlab linenums">problem.cost = @mycost;       % Cost function
function [f, store] = mycost(x, store)

    if ~isfield(store, 'Ax')
        store.Ax = A*x;       % The store memory is associated to a specific x
    end
    Ax = store.Ax;
    
    f = -x'*Ax;               % No need to cache f: cost values are cached 'under the hood'
    
end

problem.egrad = @myegrad;     % Euclidean gradient of the cost function
function [g, store] = myegrad(x, store)

    % This could be placed in a separate function
    % to avoid code duplication.
    if ~isfield(store, 'Ax')
        store.Ax = A*x;
    end
    Ax = store.Ax;
<br>    % Euclidean gradient; this is also cached 'under the hood'.<br>    g = -2*Ax;
    
end
</pre>
            <p>It is instructive to execute such code with <a target="_blank" href="http://blogs.mathworks.com/community/2010/02/01/speeding-up-your-program-through-profiling/">the
                profiler</a> activated and to look at how many times each
              instruction gets executed. You should find that the matrix-vector
              products $Ax$, which is where all the work happens, are executed
              exactly as often as they should be, and not more. You can also use
              <a href="https://github.com/NicolasBoumal/manopt/blob/master/examples/using_counters.m"
                target="_blank">Manopt counters</a> to track these products.</p>
            <div class="alert alert-info"><strong>Heads up!</strong> You should
              never assume that the gradient function, for example, will be
              called <em>after</em> the cost function (even though this is
              usually the case). Always check that the fields you use in the <code>store</code>
              structure are populated; and if they are not, call the appropriate
              functions to make up for it, as in the example above. </div>
            <div class="alert alert-info"><strong>Good to know!</strong> Which
              variables should I store? As a rule of thumb, store the
              intermediate computation results which constitute the bottleneck
              in your computation. This can usually be determined by considering
              the asymptotic time complexity of each operation. Typically,
              matrix products of large size are involved in the slowest parts.
              When in doubt, the Matlab profiler is a tremendous tool to
              identify the code bits that need special attention. In any case,
              remember that caching is optional: at the prototyping stage, it is
              best to keep things simple.</div>
            <h3><a id="hessianapproxprecons" name="hessianapproxprecons"></a>Generic
              Hessian approximations and preconditioners</h3>
            If the Hessian is complicated or costly to compute, it may be
            advantageous to resort to an approximation for it. Likewise, if the
            Hessian is poorly conditioned, it may be advantageous to provide a
            preconditioner for it (a cheap, approximate and positive definite
            inverse of the Hessian). Manopt allows for the definition of generic
            Hessian approximations and generic preconditioners. The feature is
            working, but as this is work in progress we do not have many options
            to show yet. Check out these folders if you are interested:
            <ul>
              <li><a style="font-family: monospace;" href="https://github.com/NicolasBoumal/manopt/tree/master/manopt/solvers/hessianapproximations"
                  target="_blank">/solvers/hessianapproximations</a>.</li>
              <li><a style="font-family: monospace;" href="https://github.com/NicolasBoumal/manopt/tree/master/manopt/solvers/preconditioners"
                  target="_blank">/solvers/preconditioners</a>.</li>
            </ul>
            In any case, the trust-regions solver by default works with a
            finite-difference approximation of the Hessian based on the gradient
            which has proven effective and robust over the years. See <a target="_blank"
              href="https://link.springer.com/chapter/10.1007/978-3-319-25040-3_50#">this
              paper</a> for a proof of global convergence with this
            approximation. This finite difference approximation is also covered
            by the analysis in <a href="https://academic.oup.com/imajna/advance-article/doi/10.1093/imanum/drx080/4836777"
              target="_blank">that paper</a>.<br>
            <ul>
            </ul>
          </section>
          <section id="tools">
            <div class="page-header">
              <h1>Helpful tools</h1>
            </div>
            <p>A number of generically useful tools in the context of using
              Manopt are available in <a href="https://github.com/NicolasBoumal/manopt/tree/master/manopt/tools"
                target="_blank">/<tt>manopt/tools</tt></a>. The <code>multitransp</code>
              / <code>multiprod</code> pair is code by <a target="_blank" href="http://www.mathworks.com/matlabcentral/fileexchange/8773-multiple-matrix-multiplications-with-array-expansion-enabled">Paolo
                de Leva</a> ; <code>multitrace</code> is a wrapper around <code>diagsum</code>,
              which is code by <a target="_blank" href="http://www.mathworks.com/matlabcentral/fileexchange/10062-multi-dimensional-matrix-product-outer-product-and-partial-trace">Wynton
                Moore</a>. </p>
            <table style="width: 100%;" class="table table-striped table-bordered">
              <thead>
                <tr>
                  <td style="text-align: center;"> <br>
                  </td>
                  <td>Call </td>
                  <td>Description </td>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td style="text-align: center;"> <br>
                  </td>
                  <td colspan="2" rowspan="1"><strong>Diagnostics tools</strong>
                  </td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/tools/checkdiff.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><nobr><code>checkdiff(problem, x, u)</code></nobr> </td>
                  <td>Numerical check of the directional derivatives of the cost
                    function. From a truncated Taylor expansion, we know that
                    the following holds: $$f(\operatorname{Exp}_x(tu)) -
                    \left[f(x) + t\cdot\operatorname{D}\!f(x)[u]\right] =
                    \mathcal{O}(t^2).$$ Hence, in a log-log plot with $\log(t)$
                    on the abscissa, the error should behave as $\log(t^2) =
                    2\log(t)$, i.e., we should observe a slope of 2. This tool
                    produces such a plot and tries to compute the slope of it (<em>tries</em>
                    to, because numerical errors prevent the curve to have a
                    slope of 2 everywhere even if directional derivatives are
                    correct; so you should really just inspect the plot
                    visually). If <code>x</code> and <code>u</code> are
                    omitted, they are picked at random. </td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/tools/checkgradient.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><nobr><code>checkgradient(problem, x, u)</code></nobr> </td>
                  <td>Numerical check of the gradient of the cost function.
                    Based on the statement that if the gradient exists, than it
                    is the only tangent vector field that satisfies $$\langle
                    \operatorname{grad} f(x), u\rangle_x =
                    \operatorname{D}\!f(x)[u],$$ this tool calls <code>checkdiff</code>
                    first, and it also verifies that the gradient is indeed a
                    tangent vector, by computing the norm of the difference
                    between the gradient and its projection to the tangent space
                    (if a projector is available). Of course, this should be
                    zero. </td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/tools/checkhessian.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><nobr><code>checkhessian(problem, x, u)</code></nobr> </td>
                  <td>
                    <p>Numerical check of the Hessian of the cost function. From
                      a truncated Taylor expansion, we know that the following
                      holds: $$f(\operatorname{Exp}_x(tu)) - \left[f(x) +
                      t\cdot\operatorname{D}\!f(x)[u] + \frac{t^2}{2} \cdot
                      \langle \operatorname{Hess} f(x)[u], u \rangle_x\right] =
                      \mathcal{O}(t^3).$$ Hence, in a log-log plot with
                      $\log(t)$ on the abscissa, the error should behave as
                      $\log(t^3) = 3\log(t)$, i.e., we should observe a slope of
                      3. This tool produces such a plot and tries to compute the
                      slope of it (<em>tries</em> to, because numerical errors
                      prevent the curve to have a slope of 3 everywhere even if
                      the derivatives are correct; so you should really just
                      inspect the plot visually). If <code>x</code> and <code>u</code>
                      are omitted, they are picked at random. The tool also
                      verifies that the Hessian indeed returns a tangent vector,
                      by computing the norm of the difference between
                      $\operatorname{Hess} f(x)[u]$ and its projection to the
                      tangent space (if a projector is available). Of course,
                      this should be zero.</p>
                    <p>The Hessian is a linear, symmetric operator from the
                      tangent space at $x$ to itself. To verify symmetry, this
                      tool generates two random tangent vectors $u_1$ and $u_2$
                      and computes the difference $$\langle \operatorname{Hess}
                      f(x)[u_1], u_2 \rangle_x - \langle u_1,&#160;
                      \operatorname{Hess} f(x)[u_2]\rangle_x,$$ which should be
                      zero.</p>
                    <p>See also the heads up in the blue box below.</p>
                  </td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/tools/checkretraction.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><nobr><code>checkretraction(M, x, v)</code></nobr> </td>
                  <td>For manifolds <code>M</code> which have a correct
                    exponential map <code>M.exp</code> implemented, this tool
                    allows to check the order of agreement of the retraction <code>M.retr</code>
                    with the exponential. A slope of 2 indicates the retraction
                    is a first-order approximation of the exponential (which is
                    necessary for most (all?) convergence theorems to hold.) A
                    slope of 3 indicates the retraction is second-order, which
                    may be necessary theoretically to prove convergence to
                    second-order KKT points. In practice, this may have little
                    impact. The check is conducted at point <code>x</code>
                    along direction <code>v</code>; these are generated at
                    random if omitted.</td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/tools/plotprofile.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>plotprofile(problem, x, d, t)</code></td>
                  <td>Plots the cost function along a geodesic or a retraction
                    path starting at $x$, along direction $d$. See <span style="font-family: monospace;">help
                      plotprofile</span> for more information.</td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/tools/surfprofile.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>surfprofile(problem, x, d1, d2, t1, t2)</code></td>
                  <td>Plots the cost function, lifted and restricted to a
                    2-dimensional subspace of the tangent space at $x$. See <span
                      style="font-family: monospace;">help surfprofile</span>
                    for more information.</td>
                </tr>
                <tr>
                  <td style="text-align: center;"> <br>
                  </td>
                  <td colspan="2" rowspan="1"><strong>Cost analysis</strong></td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/tools/hessianspectrum.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>lambdas = hessianspectrum(problem, x, useprecon,
                      storedb, key)</code></td>
                  <td>
                    <p>Computes the eigenvalues of the Hessian $H$ at $x$. If a
                      preconditioner $P$ is specified in the problem structure
                      and <code>useprecon</code> is set to <code>'precon'</code>,
                      the eigenvalues of the preconditioned Hessian $HP$ are
                      computed.</p>
                    <p>This function relies on <code>problem.M.vec</code> and <code>problem.M.mat</code>
                      to pass the computation to the built-in <code>eigs</code>
                      function. For the eigenvalue problem to remain symmetric
                      in the column-vector representation domain, we need <code>M.vec</code>
                      and <code>M.mat</code> to be orthonormal, i.e.,
                      isometries (see <code>matvecareisometries</code> in the <a
                        href="#manifolds">manifod section</a>). If they are not
                      isometries, computations may take longer. Indeed, let $G$
                      denote the <code>M.vec</code> operator and let $G^{-1}$
                      represent the <code>M.mat</code> operator (on the
                      appropriate domain). Then, <code>eigs</code> will compute
                      the spectrum of $GHG^{-1}$ or $GHPG^{-1}$, which are
                      identical to, respectively, the spectra of $H$ and $HP$.
                      This is only symmetric if there is no preconditioner and
                      $G^T = G^{-1}$.</p>
                    <p>If a preconditioner is used, the symmetry of the
                      eigenvalue problem is lost: $H$ and $P$ are symmetric, but
                      $HP$ is not. If <code>M.vec</code> and <code>M.mat</code>
                      are isometries and the dimension of the manifold is large,
                      it may be useful to restore symmetry by giving this tool a
                      function handle for the square root of the preconditioner,
                      $P^{1/2}$ (optional). Then, <code>eigs</code> is given
                      the problem of computing the spectrum of
                      $GP^{1/2}HP^{1/2}G^T$ (symmetric), which is equal to the
                      spectrum of $HP$. Typically, the square root of the
                      preconditioner is given via <code>problem.sqrtprecon</code>
                      (see <a href="#costdescription">cost description</a>).</p>
                    <p><code>storedb</code> and <code>key</code> are optional
                      (see <a href="#cachingsystem">caching system</a>).</p>
                  </td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/tools/hessianextreme.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>[u, lambda] = hessianextreme(problem, x, side, u0,
                      options, storedb, key)</code></td>
                  <td>
                    <p>Computes either an eigenvector / eigenvalue pair
                      associated to a largest or to a smallest eigenvalue of the
                      Hessian of the cost at <code>x</code>, for the cost as
                      described in the <code>problem</code> structure. Choose
                      an extreme side of the spectrum by setting <code>side</code>
                      either to the <code>'min'</code> or to the <code>'max'</code>
                      string. The (optional) parameters <code>u0</code>
                      (initial guess for <code>u</code>) and <code>options</code>
                      will be passed on to <code>manoptsolve</code>, then on to
                      the Manopt solver that ultimately computes the eigenpair,
                      by means of Rayleigh quotient optimization over the sphere
                      in the tangent space at <code>x</code>.</p>
                    <p><code>storedb</code> and <code>key</code> are optional
                      (see <a href="#cachingsystem">caching system</a>).</p>
                  </td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/tools/hessianmatrix.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>[H, basis] = hessianmatrix(problem, x, basis)</code></td>
                  <td>
                    <p>Given a <code>problem</code> structure, a point <code>x</code>
                      on <code>problem.M</code> and a cell <code>basis</code>
                      containing an orthonormal basis of (a subspace of) the
                      tangent space to <code>M</code> at <code>x</code>,
                      returns a matrix <code>H</code> which represents the
                      Hessian of <code>problem.cost</code> at <code>x</code>
                      in the given basis (possibly restricted to the given
                      subspace). If no basis is given, a random orthonormal
                      basis is generated for the full tangent space. In all
                      cases, the used basis is returned as second output.</p>
                  </td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/tools/criticalpointfinder.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>cp_problem = criticalpointfinder(problem)</code></td>
                  <td>Given a <code>problem</code> structure for a twice
                    continuously differentiable cost function $f(x)$, returns a
                    new problem structure for the cost function $g(x) =
                    \frac{1}{2} \| \operatorname{grad} f(x) \|^2_x$, whose
                    optima are all the critical points of the original problem.
                    Thus, running solvers on the new problem from various
                    initial points can help understand the critical points of
                    the original problem. The gradient of $g$ is computed via
                    $\operatorname{grad} g(x) = \operatorname{Hess}
                    f(x)[\operatorname{grad} f(x)]$, and an approximate Hessian
                    can also be generated.</td>
                </tr>
                <tr>
                  <td style="text-align: center;"> <br>
                  </td>
                  <td colspan="2" rowspan="1"><strong>Matrix utilities</strong>
                  </td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/tools/multiscale.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><nobr><code>B = multiscale(scale, A)</code></nobr> </td>
                  <td>For a 3D matrix <code>A</code> of size <tt>nxmxN</tt>
                    and a vector <code>scale</code> of length <tt>N</tt>,
                    returns <code>B</code>, a 3D matrix of the same size as <code>A</code>
                    such that <nobr><code>B(:, :, k) = scale(k) * A(:, :, k)</code></nobr>
                    for each <code>k</code>. </td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/tools/multitrace.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><nobr><code>tr = multitrace(A)</code></nobr> </td>
                  <td>For a 3D matrix <code>A</code> of size <tt>nxnxN</tt>,
                    returns a column vector <code>tr</code> of length <tt>N</tt>
                    such that <nobr><code>tr(k) = trace(A(:, :, k))</code></nobr>
                    for each <code>k</code>. </td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/tools/multisqnorm.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><nobr><code>sq = multisqnorm(A)</code></nobr> </td>
                  <td>For a 3D matrix <code>A</code> of size <tt>nxmxN</tt>,
                    returns a column vector <code>sq</code> of length <tt>N</tt>
                    such that <nobr><code>sq(k) = norm(A(:, :, k), 'fro')^2</code></nobr>
                    for each <code>k</code>. </td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/tools/multitransp.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><nobr><code>B = multitransp(A)</code></nobr> </td>
                  <td>For a 3D matrix <code>A</code> of size <tt>nxmxN</tt>,
                    returns <code>B</code>, a 3D matrix of size <tt>mxnxN</tt>
                    such that <nobr><code>B(:, :, k) = A(:, :, k).'</code></nobr>
                    for each <code>k</code>. </td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/tools/multihconj.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><nobr><code>B = multihconj(A)</code></nobr> </td>
                  <td>For a complex 3D matrix <code>A</code> of size <tt>nxmxN</tt>,
                    returns <code>B</code>, a complex 3D matrix of size <tt>mxnxN</tt>
                    such that <nobr><code>B(:, :, k) = A(:, :, k)'</code></nobr>
                    for each <code>k</code>. </td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/tools/multiprod.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><nobr><code>C = multiprod(A, B)</code></nobr> </td>
                  <td>For 3D matrices <code>A</code> of size <tt>nxpxN</tt>
                    and B of size <tt>pxmxN</tt>, returns <code>C</code>, a 3D
                    matrix of size <tt>nxmxN</tt> such that <nobr><code>C(:,
                        :, k) = A(:, :, k) * B(:, :, k)</code></nobr> for each <code>k</code>.
                  </td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/tools/multiskew.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>B = multiskew(A)</code></td>
                  <td>For a 3D matrix <code>A</code> of size <tt>nxnxN</tt>,
                    returns a 3D matrix <code>B</code> the same size as <code>A</code>
                    such that each slice <code>B(:, :, i)</code> is the
                    skew-symmetric part of the slice <code>A(:, :, i)</code>,
                    that is, <code>(A(:, :, i)-A(:, :, i)')/2</code>.</td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/tools/multisym.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>B = multisym(A)</code></td>
                  <td>For a 3D matrix <code>A</code> of size <tt>nxnxN</tt>,
                    returns a 3D matrix <code>B</code> the same size as <code>A</code>
                    such that each slice <code>B(:, :, i)</code> is the
                    symmetric part of the slice <code>A(:, :, i)</code>, that
                    is, <code>(A(:, :, i)+A(:, :, i).')/2</code>.</td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/tools/multiherm.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>B = multiherm(A)</code></td>
                  <td>For a complex 3D matrix <code>A</code> of size <tt>nxnxN</tt>,
                    returns a complex 3D matrix <code>B</code> the same size as
                    <code>A</code> such that each slice <code>B(:, :, i)</code>
                    is the Hermitian part of the slice <code>A(:, :, i)</code>,
                    that is, <code>(A(:, :, i)+A(:, :, i)')/2</code>.</td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/tools/dfunm.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>dfunm</code>, <code>dlogm</code>, <code>dexpm</code>,
                    <code>dsqrtm</code></td>
                  <td>Fr&#233;chet derivatives of the (built-in) matrix
                    functions <code>logm</code>, <code>expm</code> and <code>sqrtm</code>.</td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="https://github.com/NicolasBoumal/manopt/blob/master/manopt/tools/lyapunov_symmetric.m"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>lyapunov_symmetric</code></td>
                  <td>Tool to solve the Lyapunov matrix equation $AX + XA = C$
                    when $A = A^*$ (real symmetric or Hermitian), as a
                    pseudo-inverse. Can solve for more than one right-hand side
                    at a time.</td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="https://github.com/NicolasBoumal/manopt/blob/master/manopt/tools/lyapunov_symmetric_eig.m"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>lyapunov_symmetric_eig</code></td>
                  <td>Same as <code>lyapunov_symmetric</code> but the user
                    supplies the eigenvalue decomposition of $A$ instead of $A$.</td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="https://github.com/NicolasBoumal/manopt/blob/master/manopt/tools/sylvester_nochecks.m"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>sylvester_nochecks</code></td>
                  <td>Solves the Sylvester equation $AX + XB = C$, where $A$ is
                    an m-by-m matrix, $B$ is an n-by-n matrix, and $X$ and $C$
                    are two m-by-n matrices. This is a stripped-down version of
                    Matlab's own <code>sylvester</code> function that bypasses
                    any input checks. This is significantly faster for small m
                    and n, which is often useful in Manopt.</td>
                </tr>
                <tr>
                  <td style="text-align: center;"> <br>
                  </td>
                  <td colspan="2" rowspan="1"><strong>Manifold utilities</strong>
                  </td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/tools/powermanifold.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><nobr><code>Mn = powermanifold(M, n)</code></nobr> </td>
                  <td>Given <code>M</code>, a structure representing a manifold
                    $\mathcal{M}$, and <code>n</code>, an integer, returns <code>Mn</code>,
                    a structure representing the manifold $\mathcal{M}^n$. The
                    geometry is obtained by element-wise extension. Points and
                    vectors on <code>Mn</code> are represented as cells of
                    length <code>n</code>. </td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/tools/productmanifold.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><nobr><code>M = productmanifold(elements)</code></nobr> </td>
                  <td>Given <code>elements</code>, a structure with fields <code>A,
                      B, C...</code> containing structures <code>Ma, Mb, Mc...</code>
                    such that <code>Ma</code> is a structure representing a
                    manifold $\mathcal{M}_A$ etc., returns <code>M</code>, a
                    structure representing the manifold $\mathcal{M}_A \times
                    \mathcal{M}_B \times \mathcal{M}_C \times \cdots$. The
                    geometry is obtained by element-wise extension. Points and
                    vectors are represented as structures with the same field
                    names as <code>elements</code>. </td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/tools/tangentspherefactory.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>N = tangentspherefactory(M, x)</code></td>
                  <td>Given a manifold structure <code>M</code> and a point on
                    that manifold <code>x</code>, returns a manifold structure
                    <code>N</code> representing the unit sphere on the tangent
                    space to <code>M</code> at <code>x</code>. This is notably
                    used by the <a href="reference/manopt/tools/hessianextreme.html"><span
                        style="font-family: monospace;">hessianextreme</span></a>
                    tool.</td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/tools/tangentspacefactory.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>N = tangentspacefactory(M, x)</code></td>
                  <td>Given a manifold structure <code>M</code> and a point on
                    that manifold <code>x</code>, returns a manifold structure
                    <code>N</code> representing the tangent space to <code>M</code>
                    at <code>x</code>. This is notably used by the <a style="font-family: monospace;"
                      href="reference/manopt/solvers/preconditioners/preconhessiansolve.html">preconhessiansolve</a>
                    preconditioner.</td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/tools/lincomb.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>vec = lincomb(M, x, vecs, coeffs)</code></td>
                  <td>Given a cell <code>vecs</code> of $n$ tangent vectors to
                    the manifold <code>M</code> at <code>x</code> and a vector
                    <code>coeffs</code> of $n$ real coefficients, returns the
                    linear combination of the given vectors with the given
                    coefficients. The empty linear combination is the zero
                    vector at <code>x</code>.</td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/tools/tangent2vec.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>vec = tangent2vec(M, x, B, u)</code></td>
                  <td>Given a tangent vector <code>u</code> and an orthogonal
                    basis <code>B</code> on the corresponding tangent space,
                    returns the coordinates <code>vec</code> of the vector in
                    that basis. The inverse operation is <code>lincomb</code>,
                    see above.</td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/tools/grammatrix.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>G = grammatrix(M, x, vectors)</code></td>
                  <td>Given $n$ tangent vectors $v_1, \ldots, v_n$ in a cell <code>vectors</code>
                    to the manifold <code>M</code> at point <code>x</code>,
                    returns a symmetric, positive semidefinite matrix <code>G</code>
                    of size $n\times n$ such that $G_{ij} = \langle v_i, v_j
                    \rangle_x$.</td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/tools/orthogonalize.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>[orthobasis, L] = orthogonalize(M, x, basis)</code></td>
                  <td>Given a cell <code>basis</code> which contains linearly
                    independent tangent vectors to the manifold <code>M</code>
                    at <code>x</code>, returns an orthogonal basis of the
                    subspace spanned by the give basis. <code>L</code> is an
                    upper triangular matrix containing the coefficients of the
                    linear combinations needed to transform <code>basis</code>
                    into <code>orthobasis</code>. This is essentially a QR
                    factorization, via modified Gram-Schmidt.</td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/tools/orthogonalizetwice.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>[orthobasis, L] = orthogonalizetwice(M, x, basis)</code></td>
                  <td>Same as <code>orthogonalize</code>, but calls it twice in
                    sequence for (much) improved numerical stability (at twice
                    the computational cost).</td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/tools/tangentorthobasis.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>obasis = tangentorthobasis(M, x, n)</code></td>
                  <td>Given a point <code>x</code> on the manifold <code>M</code>,
                    generates <code>n</code> unit-norm, pairwise orthogonal
                    vectors in the tangent space at <code>x</code> to <code>M</code>,
                    in a cell.</td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/tools/smallestinconvexhull.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>[u_norm, coeffs, u] = smallestinconvexhull(M, x, U)</code></td>
                  <td>Computes <code>u</code>, a tangent vector to <code>M</code>
                    at <code>x</code> contained in the convex hull spanned by
                    the $n$ vectors in the cell <code>U</code>, with minimal
                    norm (according to the Riemannian metric on <code>M</code>).
                    This is obtained by solving a convex quadratic program
                    involving the Gram matrix of the given tangent vectors. The
                    quadratic program is solved using Matlab's built-in <code>quadprog</code>,
                    which requires the optimization toolbox.</td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/tools/checkmanifold.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>checkmanifold(M)</code></td>
                  <td>Tool to run a collection of tests on a manifold structure
                    produced by a factory. (This is in development.)</td>
                </tr>
                <tr>
                  <td style="text-align: center;"> <br>
                  </td>
                  <td colspan="2" rowspan="1"><strong>Solver utilities</strong></td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/tools/manoptsolve.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>[x, cost, info, options] = manoptsolve(problem, x0,
                      options)</code></td>
                  <td>Gateway function to call a Manopt solver. You may specify
                    which solver to call by setting <code>options.solver</code>
                    to a function handle corresponding to a solver. Otherwise, a
                    solver will be picked automatically. This is mainly useful
                    when programming meta algorithms which need to solve a
                    Manopt problem at some point, but one wants to leave the
                    decision of which solver to use up to the final user.</td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/tools/statsfunhelper.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>statsfun = statsfunhelper(name, fun)</code><br>
                    <code>statsfun = statsfunhelper(S)</code></td>
                  <td>Helper function to place a function handle in the field <code>options.statsfun</code>.
                    See the help about the statsfun option <a href="#statsfunhelp">earlier
                      in this tutorial</a>, and/or the help for <a style="font-family: monospace;"
                      href="reference/manopt/tools/statsfunhelper.html">statsfunhelper</a>
                    from the command line.</td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="https://github.com/NicolasBoumal/manopt/blob/master/manopt/tools/statscounters.m"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>S = statscounters(names)</code></td>
                  <td>Tool to register Manopt counters: see the <a href="https://github.com/NicolasBoumal/manopt/blob/master/examples/using_counters.m"
                      target="_blank">example file</a>. This tool can be used in
                    conjunction with the tool <a href="https://github.com/NicolasBoumal/manopt/blob/master/manopt/core/incrementcounter.m"
                      target="_blank">incrementcounter</a> to track all sorts of
                    metrics, including function calls, time spent in specific
                    parts of them, particular operations, etc.</td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="https://github.com/NicolasBoumal/manopt/blob/master/manopt/tools/incrementcounter.m"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>store = incrementcounter(store, countername,
                      increment)</code></td>
                  <td>Tool to increment a Manopt counter: see the <a href="https://github.com/NicolasBoumal/manopt/blob/master/examples/using_counters.m"
                      target="_blank">example file</a>. This tool is used in
                    conjunction with the tool <a href="https://github.com/NicolasBoumal/manopt/blob/master/manopt/tools/statscounters.m"
                      target="_blank">statscounters</a> to track all sorts of
                    metrics.</td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="https://github.com/NicolasBoumal/manopt/blob/master/manopt/tools/stopifclosedfigure.m"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>stopfun = stopifclosedfigure()</code></td>
                  <td>Interactive stopping criterion to place in <code>options.stopfun</code>.
                    Upon running the solver with this options structure, a
                    special figure opens. If at any point during the solver's
                    execution the figure is closed, the solver gracefully
                    terminates and returns the latest iterate produced so far.
                    Termination may not be immediate as the solver has to finish
                    the current iteration first.</td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="https://github.com/NicolasBoumal/manopt/blob/master/manopt/tools/stopifdeletedfile.m"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>stopfun = stopifdeletedfile(filename)</code></td>
                  <td>Interactive stopping criterion to place in <code>options.stopfun</code>.
                    Upon running the solver with this options structure, a
                    special file is created. If at any point during the solver's
                    execution the file is deleted, the solver gracefully
                    terminates and returns the latest iterate produced so far.
                    Termination may not be immediate as the solver has to finish
                    the current iteration first.</td>
                </tr>
              </tbody>
            </table>
            <div class="alert alert-info"><strong>Heads up!</strong> When using
              the <code>checkhessian</code> tool, it is important to obtain <em>both</em>
              a slope of 3 <em>and</em> to pass the symmetry test. Indeed, the
              slope test ignores the skew-symmetric part of the Hessian, since
              $x^T A x = x^T \frac{A+A^T}{2} x$. As a result, if your code for
              the Hessian has a spurious skew-symmetric part, the slope test
              will be oblivious to it. </div>
            <div class="alert alert-info"><strong>Heads up!</strong> Still
              regarding <code>checkhessian</code>: if the exponential map is
              not available for your manifold, the test may use a retraction
              instead. If the retraction is only a first-order approximation of
              the exponential, then the slope test is only expected to succeed
              at critical points of the cost function (for other points, we can
              only hope to see a slope of 2, in which case the test is
              inconclusive.)</div>
          </section>
          <section id="core">
            <div class="page-header">
              <h1>Core tools (internals)</h1>
            </div>
            <p>Internally, Manopt uses a number of tools to manipulate problem
              structures, solvers and manifolds. These tools are listed here.
              One central tool was already documented in the <a href="#cachingsystem">caching
                system description</a>: the <a href="reference/manopt/core/StoreDB.html">StoreDB
                class</a>. Because the toolbox targets flexibility in the
              problem description, the cost, gradient, Hessian etc. can be
              specified in a number of different ways in a problem structure.
              Thus, to evaluate cost-related quantities, it is best to use the
              functions below, rather than to use fields in the problem
              structure directly. For example, call <a href="reference/manopt/core/getCost.html">getCost</a>
              rather than <code>problem.cost</code>.</p>
            <p>These tools are mostly useful for solver and tool developers.</p>
            <p>The inputs <code>storedb</code> and <code>key</code> are
              usually optional. It is a good idea to pass them if they are
              available, as this allows for caching to be used.</p>
            <p>Functions called <code>canGet***</code> return true if the <code>problem</code>
              structure provides sufficient information for Manopt to compute <code>***</code>
              exactly; they return false otherwise. If false is returned, that
              does <em>not</em> imply a call to <code>get***</code> will fail.
              For example, if the problem structure specifies the gradient via <code>problem.grad</code>
              but it does not provide the Hessian, there is not enough
              information to compute the exact Hessian. Hence, <code>canGetHessian</code>
              will return false. Yet, a call to <code>getHessian</code> will
              return something; namely, a finite difference approximation of the
              Hessian for the provided inputs. Typically, solver and tool
              developers will call <code>canGet***</code> functions to assess
              what can be done with the given problem structure, and issue
              appropriate warnings as needed; then proceed to call the <code>get***</code>
              functions anyway. The general philosophy is that Manopt will try
              to do its best to answer the question asked (with the caveat that
              it might be slow or inaccurate.)</p>
            <table style="width: 100%;" class="table table-striped table-bordered">
              <thead>
                <tr>
                  <td style="text-align: center;"> <br>
                  </td>
                  <td>Call </td>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td style="text-align: center;"> <br>
                  </td>
                  <td colspan="1" rowspan="1"><strong>Cost evaluations (and
                      cost-related quantities)</strong> </td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/core/getCost.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>cost = getCost(problem, x, storedb, key)</code></td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/core/getCostGrad.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>[cost, grad] = getCostGrad(problem, x, storedb, key)</code></td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/core/getGradient.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>grad = getGradient(problem, x, storedb, key)</code></td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/core/getApproxGradient.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>agrad = getApproxGradient(problem, x, storedb, key)</code></td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/core/getPartialGradient.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>pgrad = getPartialGradient(problem, x, I, storedb,
                      key)</code></td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/core/getEuclideanGradient.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>egrad = getEuclideanGradient(problem, x, storedb,
                      key)</code></td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/core/getPartialEuclideanGradient.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>pgrad = getPartialEuclideanGradient(problem, x, I,
                      storedb, key)</code></td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/core/getSubgradient.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>subgrad = getSubgradient(problem, x, tol, storedb,
                      key)</code></td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/core/getDirectionalDerivative.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>diff = getDirectionalDerivative(problem, x, d,
                      storedb, key)</code></td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/core/getHessian.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>hess = getHessian(problem, x, d, storedb, key)</code></td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/core/getHessianFD.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>hessfd = getHessianFD(problem, x, d, storedb, key)</code></td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/core/getApproxHessian.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>approxhess = getApproxHessian(problem, x, d,
                      storedb, key)</code></td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/core/getLinesearch.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>t = getLinesearch(problem, x, d, storedb, key)</code></td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/core/getPrecon.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>Pd = getPrecon(problem, x, d, storedb, key)</code></td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/core/getSqrtPrecon.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>sqrtPd = getSqrtPrecon(problem, x, d, storedb, key)</code></td>
                </tr>
                <tr>
                  <td style="text-align: center;"> <br>
                  </td>
                  <td colspan="1" rowspan="1"><strong>Cost-related availability
                      checks (checks whether the user explicitly specified
                      these)</strong></td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/core/canGetCost.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>candoit = canGetCost(problem)</code></td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/core/canGetDirectionalDerivative.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>candoit = canGetDirectionalDerivative(problem)</code></td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/core/canGetGradient.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>candoit = canGetGradient(problem)</code></td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/core/canGetApproxGradient.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>candoit = canGetApproxGradient(problem)</code></td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/core/canGetPartialGradient.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>candoit = canGetPartialGradient(problem)</code></td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/core/canGetEuclideanGradient.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>candoit = canGetEuclideanGradient(problem)</code></td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/core/canGetPartialEuclideanGradient.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>candoit = canGetPartialEuclideanGradient(problem)</code></td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/core/canGetSubgradient.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>candoit = canGetSubgradient(problem)</code></td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/core/canGetHessian.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>candoit = canGetHessian(problem)</code></td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/core/canGetApproxHessian.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>candoit = canGetApproxHessian(problem)</code></td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/core/canGetPrecon.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>candoit = canGetPrecon(problem)</code></td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/core/canGetSqrtPrecon.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>candoit = canGetSqrtPrecon(problem)</code></td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/core/canGetLinesearch.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>candoit = canGetLinesearch(problem)</code></td>
                </tr>
                <tr>
                  <td style="text-align: center;"><br>
                  </td>
                  <td colspan="1" rowspan="1"><strong>Solver helpers</strong></td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/core/applyStatsfun.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>stats = applyStatsfun(problem, x, storedb, key,
                      options, stats)</code></td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/core/stoppingcriterion.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>[stop, reason] = stoppingcriterion(problem, x,
                      options, info, last)</code></td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/core/getGlobalDefaults.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>opts = getGlobalDefaults()</code></td>
                </tr>
                <tr>
                  <td style="text-align: center;"><a href="reference/manopt/core/mergeOptions.html"><i
                        class="icon-book">&#160;</i></a></td>
                  <td><code>opts = mergeOptions(opts1, opts2)</code></td>
                </tr>
              </tbody>
            </table>
          </section>
          <section id="reference">
            <div class="page-header">
              <h1>Reference</h1>
            </div>
            <p><a target="_blank" href="reference/index.html">A reference is
                available here</a>, to help navigate the source code of the
              toolbox. It is generated with <a target="_blank" href="http://www.artefact.tk/software/matlab/m2html/">m2html</a>.</p>
            <p>This reference is updated with each release. In between releases,
              the most up-to-date code can be browsed and downloaded on <a href="https://github.com/NicolasBoumal/manopt"
                target="_blank">GitHub</a>.</p>
          </section>
        </div>
      </div>
    </div>
    <!-- /container --><!-- Le javascript ================================================== --><!-- Placed at the end of the document so the pages load faster -->
    <script type="text/javascript" src="bootstrap/js/jquery.min.js"></script>
    <script type="text/javascript" src="bootstrap/js/bootstrap.js"></script>
    <script type="text/javascript" src="bootstrap/js/prettify.js"></script>
    <script type="text/javascript" src="bootstrap/js/lang-matlab.js"></script>
    <!--
    <script type="text/javascript" src="http://mathcache.s3.amazonaws.com/replacemath.js"> </script>    <script type="text/javascript">replaceMath( document.body ); </script>    -->
    <script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script> <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-37402854-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script> </body>
</html>
