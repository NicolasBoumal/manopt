<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of checkgradient</title>
  <meta name="keywords" content="checkgradient">
  <meta name="description" content="Checks the consistency of the cost function and the gradient.">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html v1.5 &copy; 2003-2005 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../../m2html.css">
</head>
<body>
<a name="_top"></a>
<div><a href="../../index.html">Home</a> &gt;  <a href="#">manopt</a> &gt; <a href="index.html">tools</a> &gt; checkgradient.m</div>

<!--<table width="100%"><tr><td align="left"><a href="../../index.html"><img alt="<" border="0" src="../../left.png">&nbsp;Master index</a></td>
<td align="right"><a href="index.html">Index for manopt\tools&nbsp;<img alt=">" border="0" src="../../right.png"></a></td></tr></table>-->

<h1>checkgradient
</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="box"><strong>Checks the consistency of the cost function and the gradient.</strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="box"><strong>function checkgradient(problem, x, d) </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="fragment"><pre class="comment"> Checks the consistency of the cost function and the gradient.

 function checkgradient(problem)
 function checkgradient(problem, x)
 function checkgradient(problem, x, d)

 checkgradient performs a numerical test to check that the gradient
 defined in the problem structure agrees up to first order with the cost
 function at some point x, along some direction d. The test is based on a
 truncated Taylor series (see online Manopt documentation).

 It is also tested that the gradient is indeed a tangent vector.
 
 Both x and d are optional and will be sampled at random if omitted.

 See also: <a href="checkdiff.html" class="code" title="function checkdiff(problem, x, d, force_gradient)">checkdiff</a> <a href="checkhessian.html" class="code" title="function checkhessian(problem, x, d)">checkhessian</a></pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../../matlabicon.gif)">
<li><a href="../../manopt/core/StoreDB.html" class="code" title="">StoreDB</a>	</li><li><a href="../../manopt/core/canGetCost.html" class="code" title="function candoit = canGetCost(problem)">canGetCost</a>	Checks whether the cost function can be computed for a problem structure.</li><li><a href="../../manopt/core/canGetGradient.html" class="code" title="function candoit = canGetGradient(problem)">canGetGradient</a>	Checks whether the gradient can be computed for a problem structure.</li><li><a href="../../manopt/core/canGetPartialGradient.html" class="code" title="function candoit = canGetPartialGradient(problem)">canGetPartialGradient</a>	Checks whether the partial gradient can be computed for a given problem.</li><li><a href="../../manopt/core/getGradient.html" class="code" title="function grad = getGradient(problem, x, storedb, key)">getGradient</a>	Computes the gradient of the cost function at x.</li><li><a href="checkdiff.html" class="code" title="function checkdiff(problem, x, d, force_gradient)">checkdiff</a>	Checks the consistency of the cost function and directional derivatives.</li></ul>
This function is called by:
<ul style="list-style-image:url(../../matlabicon.gif)">
<li><a href="../../examples/doubly_stochastic_denoising.html" class="code" title="function doubly_stochastic_denoising()">doubly_stochastic_denoising</a>	Find a doubly stochastic matrix closest to a given matrix, in Frobenius norm.</li></ul>
<!-- crossreference -->



<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="fragment"><pre>0001 <a name="_sub0" href="#_subfunctions" class="code">function checkgradient(problem, x, d)</a>
0002 <span class="comment">% Checks the consistency of the cost function and the gradient.</span>
0003 <span class="comment">%</span>
0004 <span class="comment">% function checkgradient(problem)</span>
0005 <span class="comment">% function checkgradient(problem, x)</span>
0006 <span class="comment">% function checkgradient(problem, x, d)</span>
0007 <span class="comment">%</span>
0008 <span class="comment">% checkgradient performs a numerical test to check that the gradient</span>
0009 <span class="comment">% defined in the problem structure agrees up to first order with the cost</span>
0010 <span class="comment">% function at some point x, along some direction d. The test is based on a</span>
0011 <span class="comment">% truncated Taylor series (see online Manopt documentation).</span>
0012 <span class="comment">%</span>
0013 <span class="comment">% It is also tested that the gradient is indeed a tangent vector.</span>
0014 <span class="comment">%</span>
0015 <span class="comment">% Both x and d are optional and will be sampled at random if omitted.</span>
0016 <span class="comment">%</span>
0017 <span class="comment">% See also: checkdiff checkhessian</span>
0018 
0019 <span class="comment">% This file is part of Manopt: www.manopt.org.</span>
0020 <span class="comment">% Original author: Nicolas Boumal, Dec. 30, 2012.</span>
0021 <span class="comment">% Contributors:</span>
0022 <span class="comment">% Change log:</span>
0023 <span class="comment">%</span>
0024 <span class="comment">%   April 3, 2015 (NB):</span>
0025 <span class="comment">%       Works with the new StoreDB class system.</span>
0026 <span class="comment">%</span>
0027 <span class="comment">%   Nov. 1, 2016 (NB):</span>
0028 <span class="comment">%       Now calls checkdiff with force_gradient = true, instead of doing an</span>
0029 <span class="comment">%       rmfield of problem.diff. This became necessary after getGradient</span>
0030 <span class="comment">%       was updated to know how to compute the gradient from directional</span>
0031 <span class="comment">%       derivatives.</span>
0032 
0033     
0034     <span class="comment">% Verify that the problem description is sufficient.</span>
0035     <span class="keyword">if</span> ~<a href="../../manopt/core/canGetCost.html" class="code" title="function candoit = canGetCost(problem)">canGetCost</a>(problem)
0036         <span class="comment">% The call to canGetPartialGradient will readily issue a warning if</span>
0037         <span class="comment">% problem.ncostterms is not defined even though it is expected.</span>
0038         <span class="keyword">if</span> ~<a href="../../manopt/core/canGetPartialGradient.html" class="code" title="function candoit = canGetPartialGradient(problem)">canGetPartialGradient</a>(problem)
0039             error(<span class="string">'getCost:checkgradient'</span>, <span class="string">'It seems no cost was provided.'</span>);
0040         <span class="keyword">else</span>
0041             error(<span class="string">'getCost:stochastic'</span>, [<span class="string">'It seems no cost was provided.\n'</span> <span class="keyword">...</span>
0042                   <span class="string">'If you intend to use a stochastic solver, you still\n'</span> <span class="keyword">...</span>
0043                   <span class="string">'need to define problem.cost to use checkgradient.'</span>]);
0044         <span class="keyword">end</span>
0045     <span class="keyword">end</span>
0046     <span class="keyword">if</span> ~<a href="../../manopt/core/canGetGradient.html" class="code" title="function candoit = canGetGradient(problem)">canGetGradient</a>(problem)
0047         warning(<span class="string">'manopt:checkgradient:nograd'</span>, <span class="keyword">...</span>
0048                 <span class="string">'It seems no gradient was provided.'</span>);
0049     <span class="keyword">end</span>
0050         
0051     x_isprovided = exist(<span class="string">'x'</span>, <span class="string">'var'</span>) &amp;&amp; ~isempty(x);
0052     d_isprovided = exist(<span class="string">'d'</span>, <span class="string">'var'</span>) &amp;&amp; ~isempty(d);
0053     
0054     <span class="keyword">if</span> ~x_isprovided &amp;&amp; d_isprovided
0055         error(<span class="string">'If d is provided, x must be too, since d is tangent at x.'</span>);
0056     <span class="keyword">end</span>
0057     
0058     <span class="comment">% If x and / or d are not specified, pick them at random.</span>
0059     <span class="keyword">if</span> ~x_isprovided
0060         x = problem.M.rand();
0061     <span class="keyword">end</span>
0062     <span class="keyword">if</span> ~d_isprovided
0063         d = problem.M.randvec(x);
0064     <span class="keyword">end</span>
0065 
0066     <span class="comment">%% Check that the gradient yields a first order model of the cost.</span>
0067     
0068     <span class="comment">% Call checkdiff with force_gradient set to true, to force that</span>
0069     <span class="comment">% function to make a gradient call.</span>
0070     <a href="checkdiff.html" class="code" title="function checkdiff(problem, x, d, force_gradient)">checkdiff</a>(problem, x, d, true);
0071     title(sprintf([<span class="string">'Gradient check.\nThe slope of the continuous line '</span> <span class="keyword">...</span>
0072                    <span class="string">'should match that of the dashed\n(reference) line '</span> <span class="keyword">...</span>
0073                    <span class="string">'over at least a few orders of magnitude for h.'</span>]));
0074     xlabel(<span class="string">'h'</span>);
0075     ylabel(<span class="string">'Approximation error'</span>);
0076     
0077     <span class="comment">%% Try to check that the gradient is a tangent vector.</span>
0078     <span class="keyword">if</span> isfield(problem.M, <span class="string">'tangent'</span>)
0079         storedb = <a href="../../manopt/core/StoreDB.html" class="code" title="">StoreDB</a>();
0080         key = storedb.getNewKey();
0081         grad = <a href="../../manopt/core/getGradient.html" class="code" title="function grad = getGradient(problem, x, storedb, key)">getGradient</a>(problem, x, storedb, key);
0082         pgrad = problem.M.tangent(x, grad);
0083         residual = problem.M.lincomb(x, 1, grad, -1, pgrad);
0084         err = problem.M.norm(x, residual);
0085         fprintf(<span class="string">'The residual should be 0, or very close. Residual: %g.\n'</span>, err);
0086         fprintf(<span class="string">'If it is far from 0, then the gradient is not in the tangent space.\n'</span>);
0087     <span class="keyword">else</span>
0088         fprintf([<span class="string">'Unfortunately, Manopt was unable to verify that the '</span><span class="keyword">...</span>
0089                  <span class="string">'gradient is indeed a tangent vector.\nPlease verify '</span> <span class="keyword">...</span>
0090                  <span class="string">'this manually or implement the ''tangent'' function '</span> <span class="keyword">...</span>
0091                  <span class="string">'in your manifold structure.'</span>]);
0092     <span class="keyword">end</span>
0093 
0094 <span class="keyword">end</span></pre></div>
<hr><address>Generated on Mon 10-Sep-2018 11:48:06 by <strong><a href="http://www.artefact.tk/software/matlab/m2html/" title="Matlab Documentation in HTML">m2html</a></strong> &copy; 2005</address>
</body>
</html>